{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data Analytics Libraries\n",
    "- Pandas\n",
    "- Numpy\n",
    "- Matplotlib\n",
    "- Datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key text.latex.preview in file C:\\Users\\rudra\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle, line 123 ('text.latex.preview : False')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.5.1/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key mathtext.fallback_to_cm in file C:\\Users\\rudra\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle, line 155 ('mathtext.fallback_to_cm : True  # When True, use symbols from the Computer Modern')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.5.1/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key savefig.jpeg_quality in file C:\\Users\\rudra\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle, line 418 ('savefig.jpeg_quality: 95       # when a jpeg is saved, the default quality parameter.')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.5.1/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key keymap.all_axes in file C:\\Users\\rudra\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle, line 466 ('keymap.all_axes : a                 # enable all axes')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.5.1/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key animation.avconv_path in file C:\\Users\\rudra\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle, line 477 ('animation.avconv_path: avconv     # Path to avconv binary. Without full path')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.5.1/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key animation.avconv_args in file C:\\Users\\rudra\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle, line 479 ('animation.avconv_args:            # Additional arguments to pass to avconv')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.5.1/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from datetime import datetime\n",
    "# %matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Project Specific Libraries\n",
    "- **Yahoo Finance (yfinance)**: Gather ticker data\n",
    "- **Backtrader Technical Analysis Library (bta-lib)**: Gather trends and pattern indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import btalib\n",
    "import yfinance as yf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Web Scraping Libraries\n",
    "- **requests**: Gather web data\n",
    "- **urllib**: Gather web data\n",
    "- **BeautifulSoup**: Extract web data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from urllib.request import urlopen, Request\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Deep Learning Libraries\n",
    "- **PyTorch**: Create neutral networks\n",
    "- **TensorBoard**: Visualize training statistics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.tensorboard as tb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Natural Language Processing Tools\n",
    "- **transformers**: Use pre-trained deep learning models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import API Keys\n",
    "- **config**: Holds all private API keys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using Yahoo Finance in order to find the ticker data. This data will include:\n",
    "\n",
    "- **Date/DateTime**: Index\n",
    "- **Open**: Price of asset at beginning of Date/Datetime\n",
    "- **High**: Highest price of asset during Date/Datetime\n",
    "- **Low**: Lowest price of asset during Date/Datetime\n",
    "- **Close**: Price of stock at end of Date/Datetime\n",
    "- **Adj Close**: Close price adjusted due to corporate actions such as dividend payouts, stock splits, or the issuance of more shares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(symbol, interval = \"1d\", start_date = \"2016-01-01\", end_date = \"2021-12-31\"):\n",
    "   \n",
    "    '''\n",
    "    Returns asset information\n",
    "\n",
    "            Parameters:\n",
    "                    symbol (string): ticker symbol for lookup\n",
    "                    interval (string): periods between datapoints (valid intervals: 1m,2m,5m,15m,30m,60m,90m,1h,1d,5d,1wk,1mo,3mo)\n",
    "                    start_date (string): format YYYY-MM-DD\n",
    "                    end_date (string): format YYYY-MM-DD\n",
    "            Returns:\n",
    "                    (DateFrame): Asset Information  \n",
    "    '''\n",
    "\n",
    "    return yf.download(symbol, start=start_date, end=end_date, interval=interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-01-04</th>\n",
       "      <td>25.652500</td>\n",
       "      <td>26.342501</td>\n",
       "      <td>25.500000</td>\n",
       "      <td>26.337500</td>\n",
       "      <td>24.220573</td>\n",
       "      <td>270597600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-05</th>\n",
       "      <td>26.437500</td>\n",
       "      <td>26.462500</td>\n",
       "      <td>25.602501</td>\n",
       "      <td>25.677500</td>\n",
       "      <td>23.613626</td>\n",
       "      <td>223164000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-06</th>\n",
       "      <td>25.139999</td>\n",
       "      <td>25.592501</td>\n",
       "      <td>24.967501</td>\n",
       "      <td>25.174999</td>\n",
       "      <td>23.151514</td>\n",
       "      <td>273829600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-07</th>\n",
       "      <td>24.670000</td>\n",
       "      <td>25.032499</td>\n",
       "      <td>24.107500</td>\n",
       "      <td>24.112499</td>\n",
       "      <td>22.174417</td>\n",
       "      <td>324377600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-08</th>\n",
       "      <td>24.637501</td>\n",
       "      <td>24.777500</td>\n",
       "      <td>24.190001</td>\n",
       "      <td>24.240000</td>\n",
       "      <td>22.291668</td>\n",
       "      <td>283192000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Open       High        Low      Close  Adj Close     Volume\n",
       "Date                                                                        \n",
       "2016-01-04  25.652500  26.342501  25.500000  26.337500  24.220573  270597600\n",
       "2016-01-05  26.437500  26.462500  25.602501  25.677500  23.613626  223164000\n",
       "2016-01-06  25.139999  25.592501  24.967501  25.174999  23.151514  273829600\n",
       "2016-01-07  24.670000  25.032499  24.107500  24.112499  22.174417  324377600\n",
       "2016-01-08  24.637501  24.777500  24.190001  24.240000  22.291668  283192000"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = get_data(\"AAPL\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Construction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Technical Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A part of this study is to try and see if a model can use technical analysis (TA) as a way to create a trading strategy\n",
    "\n",
    "Technical analysis is the study of trends and patterns in order to predict profitable trading decisions. There are 4 types of indictors we will in this study:\n",
    "\n",
    "- trend indictors\n",
    "- momentum indicators\n",
    "- volatility indicators\n",
    "- volume indicators. \n",
    "\n",
    "Typically, traders use only a 2-3 indictors for their strategy, however, our job is to also see if a model can determine which indictors are more important when making these decisions as well.\n",
    "\n",
    "In order to add TA to our data, we will be using bta-lib.\n",
    "\n",
    "Below, we will go in depth into a few indictors and how they are used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Moving Average\n",
    "\n",
    "The simple moving average indictor is a trend indictor that finds the average price within a certain window of time. This helps smooth out the noise in price changes and helps trades seen the general trend of the asset's price.\n",
    "\n",
    "Many traders also use two different moving averages on the same asset. One moving average would have a longer period than the other. In order to buy, the shorter moving average would have to greater than the longer moving average, indicating that there is a rapid change in price upwards. The same is true vice versa.\n",
    "\n",
    "We will test if the model could potentially recognize this pattern and gauge if it is useful.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![SMA](images/SMA.PNG)\n",
    "\n",
    "This chart shows Apple stock prices using the moving average indictors. The purple line shows the short term moving average of 12 days and the yellow line shows the long term moving average of 26 days. The green \"up\" arrow shows where a trader would buy and the red \"down\" arrow shows where a trader would sell using this strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_MA(data, short_period=12, long_period=26):\n",
    "\n",
    "    '''\n",
    "    Adds Moving Averages to asset data\n",
    "\n",
    "        Parameters:\n",
    "                data (DataFrame): asset data\n",
    "                short_period (int): period over moving average taken (<long_period)\n",
    "                long_period (int): period over moving average taken (>short_period)\n",
    "\n",
    "        Returns:\n",
    "                (DateFrame): Asset Information\n",
    "    '''\n",
    "\n",
    "    # get Moving Averages\n",
    "    ShortMA = btalib.sma(data, period=short_period)\n",
    "    LongMA = btalib.sma(data, period=long_period)\n",
    "\n",
    "    # add to current data\n",
    "    data[\"ShortMA\"] = ShortMA.df\n",
    "    data[\"LongMA\"] = LongMA.df\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exponential Moving Average\n",
    "\n",
    "The exponential moving average is similar to the simple moving average, however, it gives higher weigh to more recent changes within the window of time. This could better help find short term price trends than the simple moving average.\n",
    "\n",
    "Note: may only use this rather than the simple moving average for the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![EMA](images/EMA.PNG)\n",
    "\n",
    "This chart shows Apple stock prices using the exponential moving average indictors. The purple line shows the short term moving average of 12 days and the yellow line shows the long term moving average of 26 days. The green \"up\" arrow shows where a trader would buy and the red \"down\" arrow shows where a trader would sell using this strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_EMA(data, short_period=12, long_period=26):\n",
    "    '''\n",
    "    Adds Exponential Moving Averages to asset data\n",
    "\n",
    "        Parameters:\n",
    "                data (DataFrame): asset data\n",
    "                short_period (int): period over moving average taken (<long_period)\n",
    "                long_period (int): period over moving average taken (>short_period)\n",
    "\n",
    "        Returns:\n",
    "                (DateFrame): Asset Information \n",
    "    '''\n",
    "    # get Exponential Moving Averages\n",
    "    ShortEMA = btalib.ema(data, period=12)\n",
    "    LongEMA = btalib.ema(data, period=26)\n",
    "    \n",
    "    # add to data\n",
    "    data[\"ShortEMA\"] = ShortEMA.df\n",
    "    data[\"LongEMA\"] = LongEMA.df\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bollinger Bands\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Bollinger Bands indictors is a kind of volatility indictor which uses the moving average over a portion of days and finds a certain standard deviation above and below that moving average. This indictor relies on the theory of mean reversion where asset prices, after spikes in price changes, revert towards the moving average of price. This indictor also shows how volatile an asset is; if the bands are farther apart, then more volatile the asset is. Traders may use this strategy by buying an asset when the price reaches the lower standard deviation and then sell at the higher standard deviation. Usually, traders use 2 standard deviations away from the mean and have a moving average window of 20 periods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Simple Bollinger Bands](images/simpleBBands.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purple lines are two standard deviations and the yellow line is the moving average."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, this strategy by itself or unaltered is not perfect, as it may miss out on trends. However, with stop losses (selling if price drops below certain value), band line slopes, and pattern recognition, this strategy may help the model learn more about correct buy and sell signals.\n",
    "\n",
    "Another possible way to improve this strategy is to add another set of Bollinger Bands that have a different standard deviation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Double Bollienger Bands](images/doubleBBands.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the added blue lines are one standard deviation away from moving average and in this case, a strategy could be that a trader could buy at the lower wider (2 std) line and sell when the price touches the upper wider line and then falls below the upper narrow line (1 std)\n",
    "\n",
    "More research is needed to be done in this case but this might help model learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_BBands(data, period=20, wider_std=2, narrow_std=1):\n",
    "    \n",
    "    '''\n",
    "    Adds Bollinger Bands to asset data\n",
    "\n",
    "        Parameters:\n",
    "                data (DataFrame): ticker symbol for lookup\n",
    "                period (int): period over moving average taken\n",
    "                wider_std (float): standard deviation of wider bands (>narrow_std)\n",
    "                narrow_std (float): standard deviation of narrow bands (<wider_std)\n",
    "\n",
    "\n",
    "        Returns:\n",
    "                (DateFrame): Asset Information \n",
    "    '''\n",
    "\n",
    "    try:\n",
    "        # get Bollinger Bands (regular and narrowed)\n",
    "        mid, top, bot = btalib.bbands(data, period = period, devs = wider_std)\n",
    "        mid_narrow, top_narrow, bot_narrow = btalib.bbands(data, period = period, devs = narrow_std)\n",
    "    except ValueError:\n",
    "        print(\"Data broken...check timeframe\")\n",
    "        return None\n",
    "\n",
    "    # add to asset data\n",
    "    data[\"Mid BBand\"] = list(mid)\n",
    "    data[\"Top BBand\"] = list(top)\n",
    "    data[\"Bot BBand\"] = list(bot)\n",
    "    data[\"Volatility\"] = data[\"Top BBand\"] - data[\"Bot BBand\"]\n",
    "    \n",
    "    data[\"Mid BBand Narrow\"] = list(mid_narrow)\n",
    "    data[\"Top BBand Narrow\"] = list(top_narrow)\n",
    "    data[\"Bot BBand Narrow\"] = list(bot_narrow)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relative Strength Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Relative Strength Index (RSI) is a momentum indictor that shows how oversold or overbought an asset is. Typically traders would sell when RSI is above 70 as the asset would be considered overbought and overvalued and buy when RSI is below 30 as the asset would then be considered oversold and undervalued. It is calculated using \n",
    "\n",
    "$100-(100/(1+(Avg Gain/Avg Loss)))$ \n",
    "\n",
    "This average gain and loss is computed over a given period. This period is typically 14 days."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![RSI](images/RSI.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see that RSI does a decent job at capturing trends. The goal of the model is to create its own interpretation of RSI if useful for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_RSI(data, period=14):\n",
    "    '''\n",
    "    Adds RSI to asset data\n",
    "\n",
    "        Parameters:\n",
    "                data (DataFrame): ticker symbol for lookup\n",
    "                period (int): period over averages taken\n",
    "\n",
    "        Returns:\n",
    "                (DateFrame): Asset Information \n",
    "    '''\n",
    "    rsi = btalib.rsi(data, period = period)\n",
    "\n",
    "    data[\"RSI\"] = rsi.df\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moving Average Convergence Divergence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Moving Average Convergence Divergence (MACD) is a trend/momentum indictor that finds the difference between two exponential moving averages (EMA). The MACD provides 3 metrics: MACD line, Signal line, and a histogram. The histogram represents how much the difference is between the two EMA's. Traders would usually buy when the MACD line crosses above the Signal line. In the case of the code, the model should buy when MACD changes from negative to positive and sell vice versa. The typical EMA periods are 12 periods and 26 periods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![MACD](images/MACD.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the chart, the blue line is the MACD line and the orange line is the signal line. We see that this can see trends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_MACD(data):\n",
    "    '''\n",
    "    Adds MACD to asset data\n",
    "\n",
    "        Parameters:\n",
    "                data (DataFrame): ticker symbol for lookup\n",
    "\n",
    "        Returns:\n",
    "                (DateFrame): Asset Information \n",
    "    '''\n",
    "    MACD = data[\"ShortEMA\"] - data[\"LongEMA\"]\n",
    "\n",
    "    data[\"MACD\"] = MACD\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rate of Change"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rate of change (ROC) is a momentum indictor that gets the percent difference between the current price and a price from a past period. If ROC changes from negative to positive, then buy, however, if ROC changes from positive to negative, then sell. Typically, traders use the current price and the last 12th price to calculate this value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ROC](images/ROC.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using ROC, we are able to pick up trends as well. The ROC chart is the blue line chart below price chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ROC(data, period=12):\n",
    "    '''\n",
    "    Adds Rate of Change to asset data\n",
    "\n",
    "        Parameters:\n",
    "                data (DataFrame): ticker symbol for lookup\n",
    "\n",
    "        Returns:\n",
    "                (DateFrame): Asset Information \n",
    "    '''\n",
    "    roc = btalib.roc(data, period=period)\n",
    "    data[\"ROC\"] = roc.df\n",
    "    \n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_TA(data):\n",
    "#     data = get_BBands(data)\n",
    "#     data = get_RSI(data)\n",
    "#     data = get_EMA(data)\n",
    "#     data = get_MA(data)\n",
    "#     data = get_MACD(data)\n",
    "#     data = get_ROC(data)\n",
    "\n",
    "#     #data = get_spy_return(data)\n",
    "#     data = get_t_bond(data)   \n",
    "\n",
    "#     return data\n",
    "\n",
    "# def plot_TA(data, bbands=False, rsi=False, ema=False, ma=False, macd=False, roc=)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Market Correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard & Poor's 500\n",
    "\n",
    "The Standard & Poor's 500 Index (S&P 500) is considered to be a measure of market health. This is because the S&P 500 tracks the performance of the top 500 companies in the US market. If these companies are not doing well, the S&P 500 will drop and also be a good indictor that the rest of the market may not being doing well either. This can be used to compare to the current stock and if the trend of the S&P 500 is downwards, then it is also likely that the asset in question also has a downward trend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spy_return(data):\n",
    "    '''\n",
    "    Adds S&P 500 to asset data\n",
    "\n",
    "        Parameters:\n",
    "                data (DataFrame): ticker symbol for lookup\n",
    "\n",
    "        Returns:\n",
    "                (DateFrame): Asset Information \n",
    "    '''\n",
    "    spy_data = get_data(\"SPY\")\n",
    "    closes = spy_data[\"Close\"]\n",
    "\n",
    "    #returns = [y - x for x,y in zip(closes,closes[3:])]\n",
    "    #data[\"SPY_returns\"] = returns\n",
    "    \n",
    "    data[\"SPY_returns\"] = closes\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treasury Bond Yield\n",
    "\n",
    "Treasury bonds (T-bonds) are government based, \"zero-risk,\" bonds. Treasury bonds prices are inversely correlated with interest rates. If interest rates rise, then bond prices will fall and investors would rather save their money rather than invest, which also causes the demand in the market to fall. In order to increase demand for these bonds and the market during times of high interest rates, bonds also have higher yields.\n",
    "\n",
    "This means that yields are correlated with interest rates. If we can capture the treasury bond yield, then we will also know the trend in interest rates and may make better market decisions. In this case, we will be using the 10-year treasury bond yield rates as a feature in our model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_t_bond(data):\n",
    "    '''\n",
    "    Adds T Bond Yield to asset data\n",
    "\n",
    "        Parameters:\n",
    "                data (DataFrame): ticker symbol for lookup\n",
    "\n",
    "        Returns:\n",
    "                (DateFrame): Asset Information \n",
    "    '''\n",
    "    t_data = get_data(\"^TNX\")\n",
    "    data[\"Treasury_Yield_10_Years\"] = t_data[\"Close\"]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Market Sentiment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Asset News Headlines\n",
    "\n",
    "Many investors look towards the news in order to find out how well the asset is performing and what future price changes may look like. We can scrape these new articles using an API and website. The API we will be using is the Finnhub API. The Finnhub API has a feature that allows for historical headlines however there are not many and they do not go far back in time. The Finviz website gives daily news updates for any ticket symbol that can be scraped. These two sources of new headlines can be used for sentiment analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_past_headlines(symbol, end_date = \"2022-01-21\"):\n",
    "    end_date_news = datetime.strptime(end_date, '%Y-%m-%d')\n",
    "    start_news_date = end_date_news - dt.timedelta(days=365)\n",
    "    start_news_date  = start_news_date.strftime(\"%Y-%m-%d\")\n",
    "    r = requests.get('https://finnhub.io/api/v1/company-news?symbol={}&from={}&to{}&token={}'.format(symbol, start_news_date, end_date, FINNHUB_API_KEY))\n",
    "    df = pd.DataFrame()\n",
    "    df[\"datetime\"]=pd.to_datetime([i[\"datetime\"] for i in r.json()], unit='s')\n",
    "    df[\"datetime\"] = df[\"datetime\"].dt.date\n",
    "    df[\"headline\"] = [i[\"headline\"] for i in r.json()]\n",
    "    df[\"summary\"] = [i[\"summary\"] for i in r.json()]\n",
    "\n",
    "    return df\n",
    "\n",
    "def get_current_headlines(symbol):\n",
    "\n",
    "    finwiz_url = 'https://finviz.com/quote.ashx?t='\n",
    "\n",
    "    url = finwiz_url + symbol\n",
    "    req = Request(url=url,headers={'user-agent': 'my-app/0.0.1'}) \n",
    "    response = urlopen(req)    \n",
    "    # Read the contents of the file into 'html'\n",
    "    html = BeautifulSoup(response, \"lxml\")\n",
    "    # Find 'news-table' in the Soup and load it into 'news_table'\n",
    "    news_table = html.find(id='news-table')\n",
    "    \n",
    "    parsed_news = []\n",
    "\n",
    "    for x in news_table.findAll('tr'):\n",
    "        # read the text from each tr tag into text\n",
    "        # get text from a only\n",
    "        text = x.a.get_text() \n",
    "        \n",
    "        # split text in the td tag into a list \n",
    "        date_scrape = x.td.text.split()\n",
    "        # if the length of 'date_scrape' is 1, load 'time' as the only element\n",
    "\n",
    "        if len(date_scrape) == 2:\n",
    "            date = date_scrape[0]\n",
    "            time = date_scrape[1]\n",
    "\n",
    "            date = datetime.strptime(date, '%b-%d-%y').date()\n",
    " \n",
    "        else:\n",
    "            date = parsed_news[-1][0]\n",
    "            time = date_scrape[0]\n",
    "\n",
    "        summary = \"\"\n",
    "        parsed_news.append([date,text,summary])\n",
    "    \n",
    "    news = pd.DataFrame(parsed_news, columns=[\"datetime\", \"headline\", \"summary\"])\n",
    "\n",
    "    return news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "current = get_current_headlines(\"AAPL\")\n",
    "past = get_past_headlines(\"AAPL\")\n",
    "\n",
    "news = pd.concat([current, past])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>headline</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-03-30</td>\n",
       "      <td>Apple Cuts iPhone Trade-In Prices. That Could ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-03-30</td>\n",
       "      <td>3 reasons why Apple stock is on fire</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-03-30</td>\n",
       "      <td>Apple's market value is nearing $3 trillion af...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-03-30</td>\n",
       "      <td>The Zacks Analyst Blog Highlights Apple, The P...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-03-30</td>\n",
       "      <td>UPDATE 1-Intel CEO earned 1,711 times more tha...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>2022-03-25</td>\n",
       "      <td>Apple to let people subscribe to iPhones, repo...</td>\n",
       "      <td>Apple could offer the iPhone in a new subscrip...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>2022-03-25</td>\n",
       "      <td>EXCLUSIVE-Apple has not fully complied with or...</td>\n",
       "      <td>Apple has yet to fully comply with an order to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>2022-03-25</td>\n",
       "      <td>After Hours Most Active for Mar 25, 2022 : BBD...</td>\n",
       "      <td>The NASDAQ 100 After Hours Indicator is down -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>2022-03-25</td>\n",
       "      <td>U.S. Stocks Mixed as Biden's Europe Trip Produ...</td>\n",
       "      <td>U.S. stocks opened mixed on Friday as Presiden...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>2022-03-25</td>\n",
       "      <td>U.S. Tech Giants Face Tough New Rules in Europe</td>\n",
       "      <td>Tough new rules being adopted by the European ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>321 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       datetime                                           headline  \\\n",
       "0    2022-03-30  Apple Cuts iPhone Trade-In Prices. That Could ...   \n",
       "1    2022-03-30               3 reasons why Apple stock is on fire   \n",
       "2    2022-03-30  Apple's market value is nearing $3 trillion af...   \n",
       "3    2022-03-30  The Zacks Analyst Blog Highlights Apple, The P...   \n",
       "4    2022-03-30  UPDATE 1-Intel CEO earned 1,711 times more tha...   \n",
       "..          ...                                                ...   \n",
       "216  2022-03-25  Apple to let people subscribe to iPhones, repo...   \n",
       "217  2022-03-25  EXCLUSIVE-Apple has not fully complied with or...   \n",
       "218  2022-03-25  After Hours Most Active for Mar 25, 2022 : BBD...   \n",
       "219  2022-03-25  U.S. Stocks Mixed as Biden's Europe Trip Produ...   \n",
       "220  2022-03-25    U.S. Tech Giants Face Tough New Rules in Europe   \n",
       "\n",
       "                                               summary  \n",
       "0                                                       \n",
       "1                                                       \n",
       "2                                                       \n",
       "3                                                       \n",
       "4                                                       \n",
       "..                                                 ...  \n",
       "216  Apple could offer the iPhone in a new subscrip...  \n",
       "217  Apple has yet to fully comply with an order to...  \n",
       "218  The NASDAQ 100 After Hours Indicator is down -...  \n",
       "219  U.S. stocks opened mixed on Friday as Presiden...  \n",
       "220  Tough new rules being adopted by the European ...  \n",
       "\n",
       "[321 rows x 3 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get News Sentiment\n",
    "Using the new headlines pulled from the API and website, we can get the sentiment of the asset on each period. We can use a pre-trained BERT model to get the sentiment of the headline's text. There is a BERT model that is trained on financial data. We will be using this model. This sentiment may be able to help the model make better trading decisions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment(data, news):\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"ProsusAI/finbert\")\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\"ProsusAI/finbert\")\n",
    "\n",
    "\n",
    "\n",
    "    inputs = tokenizer(news[\"headline\"].tolist(), padding = True, truncation = True, return_tensors='pt')\n",
    "\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "    predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "\n",
    "    positive = predictions[:, 0].tolist()\n",
    "    negative = predictions[:, 1].tolist()\n",
    "    neutral = predictions[:, 2].tolist()\n",
    "\n",
    "    table = {'Headline':news[\"headline\"].tolist(),\n",
    "            \"Positive\":positive,\n",
    "            \"Negative\":negative, \n",
    "            \"Neutral\":neutral}\n",
    "        \n",
    "    df = pd.DataFrame(table, columns = [\"Headline\", \"Positive\", \"Negative\", \"Neutral\"])\n",
    "    news[\"Sentiment\"] = df[\"Positive\"] - df[\"Negative\"]\n",
    "    \n",
    "    news.drop(['headline', 'summary'], axis=1, inplace=True)\n",
    "\n",
    "    result = news.groupby(['datetime']).mean()\n",
    "    \n",
    "    dates_in_data = [i.strftime('%Y-%m-%d') for i in data.index]\n",
    "\n",
    "    \n",
    "    result.index = [i.strftime('%Y-%m-%d') for i in result.index]\n",
    "\n",
    "    result = result[result.index.isin(dates_in_data)]\n",
    "    number_missing = data.shape[0]-len(result)\n",
    "    missing = [0] * number_missing\n",
    "    senti = missing + result[\"Sentiment\"].tolist()\n",
    "\n",
    "    data[\"Sentiment\"] = senti\n",
    "\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_TA(data):\n",
    "    data = get_BBands(data)\n",
    "    data = get_RSI(data)\n",
    "    data = get_EMA(data)\n",
    "    data = get_MA(data)\n",
    "    data = get_MACD(data)\n",
    "    data = get_ROC(data)\n",
    "\n",
    "    data = get_spy_return(data)\n",
    "    data = get_t_bond(data)   \n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.researchgate.net/publication/324802031_Algorithmic_Financial_Trading_with_Deep_Convolutional_Neural_Networks_Time_Series_to_Image_Conversion_Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels(data, window_size=11):\n",
    "    counter_row = 0 #counterRow\n",
    "    num_periods = len(data) #numberOfDaysInFile\n",
    "    labels = np.zeros(num_periods)\n",
    "    labels[:] = np.nan\n",
    "\n",
    "    while(counter_row < num_periods):\n",
    "        counter_row += 1\n",
    "        if(counter_row > window_size):\n",
    "            window_begin_index = counter_row - window_size\n",
    "            window_ending_index = counter_row\n",
    "            window_middle_index = (window_ending_index + window_begin_index) // 2\n",
    "\n",
    "            min_number = np.inf\n",
    "            min_index = -1\n",
    "\n",
    "            max_number = -1 #price can not be negative?\n",
    "            max_index = -1\n",
    "        \n",
    "            for i in range(window_begin_index, window_ending_index):\n",
    "                number = data.iloc[i][\"Close\"]\n",
    "                if number < min_number:\n",
    "                    min_number = number\n",
    "                    min_index = i\n",
    "                if number > max_number:\n",
    "                    max_number = number\n",
    "                    max_index = i\n",
    "            if(max_index == window_middle_index):\n",
    "                labels[window_middle_index] = 0 # sell\n",
    "            elif(min_index == window_middle_index):\n",
    "                labels[window_middle_index] = 1 #buy\n",
    "            else:\n",
    "                labels[window_middle_index] = 2 #no action\n",
    "\n",
    "    data[\"Target\"] = labels\n",
    "    data[\"Target\"] =  data[\"Target\"].fillna(2)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile all Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "getting TA\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "getting news\n",
      "calculating sentiment\n",
      "getting true labels\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Mid BBand</th>\n",
       "      <th>Top BBand</th>\n",
       "      <th>Bot BBand</th>\n",
       "      <th>Volatility</th>\n",
       "      <th>...</th>\n",
       "      <th>ShortEMA</th>\n",
       "      <th>LongEMA</th>\n",
       "      <th>ShortMA</th>\n",
       "      <th>LongMA</th>\n",
       "      <th>MACD</th>\n",
       "      <th>ROC</th>\n",
       "      <th>SPY_returns</th>\n",
       "      <th>Treasury_Yield_10_Years</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-01-04</th>\n",
       "      <td>25.652500</td>\n",
       "      <td>26.342501</td>\n",
       "      <td>25.500000</td>\n",
       "      <td>26.337500</td>\n",
       "      <td>24.220575</td>\n",
       "      <td>270597600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>201.020004</td>\n",
       "      <td>2.245</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-05</th>\n",
       "      <td>26.437500</td>\n",
       "      <td>26.462500</td>\n",
       "      <td>25.602501</td>\n",
       "      <td>25.677500</td>\n",
       "      <td>23.613628</td>\n",
       "      <td>223164000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>201.360001</td>\n",
       "      <td>2.248</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-06</th>\n",
       "      <td>25.139999</td>\n",
       "      <td>25.592501</td>\n",
       "      <td>24.967501</td>\n",
       "      <td>25.174999</td>\n",
       "      <td>23.151522</td>\n",
       "      <td>273829600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>198.820007</td>\n",
       "      <td>2.177</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-07</th>\n",
       "      <td>24.670000</td>\n",
       "      <td>25.032499</td>\n",
       "      <td>24.107500</td>\n",
       "      <td>24.112499</td>\n",
       "      <td>22.174417</td>\n",
       "      <td>324377600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>194.050003</td>\n",
       "      <td>2.153</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-08</th>\n",
       "      <td>24.637501</td>\n",
       "      <td>24.777500</td>\n",
       "      <td>24.190001</td>\n",
       "      <td>24.240000</td>\n",
       "      <td>22.291672</td>\n",
       "      <td>283192000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>191.919998</td>\n",
       "      <td>2.130</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Open       High        Low      Close  Adj Close     Volume  \\\n",
       "Date                                                                           \n",
       "2016-01-04  25.652500  26.342501  25.500000  26.337500  24.220575  270597600   \n",
       "2016-01-05  26.437500  26.462500  25.602501  25.677500  23.613628  223164000   \n",
       "2016-01-06  25.139999  25.592501  24.967501  25.174999  23.151522  273829600   \n",
       "2016-01-07  24.670000  25.032499  24.107500  24.112499  22.174417  324377600   \n",
       "2016-01-08  24.637501  24.777500  24.190001  24.240000  22.291672  283192000   \n",
       "\n",
       "            Mid BBand  Top BBand  Bot BBand  Volatility  ...  ShortEMA  \\\n",
       "Date                                                     ...             \n",
       "2016-01-04        NaN        NaN        NaN         NaN  ...       NaN   \n",
       "2016-01-05        NaN        NaN        NaN         NaN  ...       NaN   \n",
       "2016-01-06        NaN        NaN        NaN         NaN  ...       NaN   \n",
       "2016-01-07        NaN        NaN        NaN         NaN  ...       NaN   \n",
       "2016-01-08        NaN        NaN        NaN         NaN  ...       NaN   \n",
       "\n",
       "            LongEMA  ShortMA  LongMA  MACD  ROC  SPY_returns  \\\n",
       "Date                                                           \n",
       "2016-01-04      NaN      NaN     NaN   NaN  NaN   201.020004   \n",
       "2016-01-05      NaN      NaN     NaN   NaN  NaN   201.360001   \n",
       "2016-01-06      NaN      NaN     NaN   NaN  NaN   198.820007   \n",
       "2016-01-07      NaN      NaN     NaN   NaN  NaN   194.050003   \n",
       "2016-01-08      NaN      NaN     NaN   NaN  NaN   191.919998   \n",
       "\n",
       "            Treasury_Yield_10_Years  Sentiment  Target  \n",
       "Date                                                    \n",
       "2016-01-04                    2.245          0     2.0  \n",
       "2016-01-05                    2.248          0     2.0  \n",
       "2016-01-06                    2.177          0     2.0  \n",
       "2016-01-07                    2.153          0     1.0  \n",
       "2016-01-08                    2.130          0     2.0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "symbol = \"AAPL\"\n",
    "\n",
    "data = get_data(symbol)\n",
    "data.head()\n",
    "\n",
    "print(\"getting TA\")\n",
    "data = get_TA(data)\n",
    "\n",
    "print(\"getting news\")\n",
    "current = get_current_headlines(symbol)\n",
    "past = get_past_headlines(symbol)\n",
    "\n",
    "news = pd.concat([current, past])\n",
    "print(\"calculating sentiment\")\n",
    "\n",
    "data = get_sentiment(data, news)\n",
    "\n",
    "print(\"getting true labels\")\n",
    "data = get_labels(data, window_size=5)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_labels(data, symbol):\n",
    "\n",
    "    df = data.copy()\n",
    "    df[\"Buy\"] = [df.iloc[i][\"Close\"] if df.iloc[i][\"Target\"] == 1.0 else np.nan for i in range(len(df[\"Target\"]))]\n",
    "    df[\"Sell\"] = [df.iloc[i][\"Close\"] if df.iloc[i][\"Target\"] == 0.0 else np.nan for i in range(len(df[\"Target\"]))]\n",
    "\n",
    "    #df[\"Sell\"] = [df[\"Close\"] if i == 0.0 else np.nan for i in df[\"Target\"]]\n",
    "    fig = plt.figure(figsize=(8, 6))\n",
    "    plt.plot(df[\"Close\"], color = \"blue\", alpha = .5)\n",
    "    \n",
    "    if(not df[\"Buy\"].isnull().all()):\n",
    "        plt.scatter(df.index, df[\"Buy\"], color = 'green', marker=\"^\", alpha=1)\n",
    "    if(not df[\"Sell\"].isnull().all()):\n",
    "        plt.scatter(df.index, df[\"Sell\"], color = 'red', marker=\"v\", alpha=1)\n",
    "\n",
    "    plt.show() \n",
    "    # fig.savefig('ML_charts/{}_target_chart.png'.format(symbol))\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_labels(data, \"AAPL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Mid BBand</th>\n",
       "      <th>Top BBand</th>\n",
       "      <th>Bot BBand</th>\n",
       "      <th>Volatility</th>\n",
       "      <th>...</th>\n",
       "      <th>ShortEMA</th>\n",
       "      <th>LongEMA</th>\n",
       "      <th>ShortMA</th>\n",
       "      <th>LongMA</th>\n",
       "      <th>MACD</th>\n",
       "      <th>ROC</th>\n",
       "      <th>SPY_returns</th>\n",
       "      <th>Treasury_Yield_10_Years</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-01-04</th>\n",
       "      <td>25.652500</td>\n",
       "      <td>26.342501</td>\n",
       "      <td>25.500000</td>\n",
       "      <td>26.337500</td>\n",
       "      <td>24.220575</td>\n",
       "      <td>270597600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>201.020004</td>\n",
       "      <td>2.245</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-05</th>\n",
       "      <td>26.437500</td>\n",
       "      <td>26.462500</td>\n",
       "      <td>25.602501</td>\n",
       "      <td>25.677500</td>\n",
       "      <td>23.613628</td>\n",
       "      <td>223164000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>201.360001</td>\n",
       "      <td>2.248</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-06</th>\n",
       "      <td>25.139999</td>\n",
       "      <td>25.592501</td>\n",
       "      <td>24.967501</td>\n",
       "      <td>25.174999</td>\n",
       "      <td>23.151522</td>\n",
       "      <td>273829600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>198.820007</td>\n",
       "      <td>2.177</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-07</th>\n",
       "      <td>24.670000</td>\n",
       "      <td>25.032499</td>\n",
       "      <td>24.107500</td>\n",
       "      <td>24.112499</td>\n",
       "      <td>22.174417</td>\n",
       "      <td>324377600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>194.050003</td>\n",
       "      <td>2.153</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-08</th>\n",
       "      <td>24.637501</td>\n",
       "      <td>24.777500</td>\n",
       "      <td>24.190001</td>\n",
       "      <td>24.240000</td>\n",
       "      <td>22.291672</td>\n",
       "      <td>283192000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>191.919998</td>\n",
       "      <td>2.130</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Open       High        Low      Close  Adj Close     Volume  \\\n",
       "Date                                                                           \n",
       "2016-01-04  25.652500  26.342501  25.500000  26.337500  24.220575  270597600   \n",
       "2016-01-05  26.437500  26.462500  25.602501  25.677500  23.613628  223164000   \n",
       "2016-01-06  25.139999  25.592501  24.967501  25.174999  23.151522  273829600   \n",
       "2016-01-07  24.670000  25.032499  24.107500  24.112499  22.174417  324377600   \n",
       "2016-01-08  24.637501  24.777500  24.190001  24.240000  22.291672  283192000   \n",
       "\n",
       "            Mid BBand  Top BBand  Bot BBand  Volatility  ...  ShortEMA  \\\n",
       "Date                                                     ...             \n",
       "2016-01-04        NaN        NaN        NaN         NaN  ...       NaN   \n",
       "2016-01-05        NaN        NaN        NaN         NaN  ...       NaN   \n",
       "2016-01-06        NaN        NaN        NaN         NaN  ...       NaN   \n",
       "2016-01-07        NaN        NaN        NaN         NaN  ...       NaN   \n",
       "2016-01-08        NaN        NaN        NaN         NaN  ...       NaN   \n",
       "\n",
       "            LongEMA  ShortMA  LongMA  MACD  ROC  SPY_returns  \\\n",
       "Date                                                           \n",
       "2016-01-04      NaN      NaN     NaN   NaN  NaN   201.020004   \n",
       "2016-01-05      NaN      NaN     NaN   NaN  NaN   201.360001   \n",
       "2016-01-06      NaN      NaN     NaN   NaN  NaN   198.820007   \n",
       "2016-01-07      NaN      NaN     NaN   NaN  NaN   194.050003   \n",
       "2016-01-08      NaN      NaN     NaN   NaN  NaN   191.919998   \n",
       "\n",
       "            Treasury_Yield_10_Years  Sentiment  Target  \n",
       "Date                                                    \n",
       "2016-01-04                    2.245          0     2.0  \n",
       "2016-01-05                    2.248          0     2.0  \n",
       "2016-01-06                    2.177          0     2.0  \n",
       "2016-01-07                    2.153          0     1.0  \n",
       "2016-01-08                    2.130          0     2.0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Mid BBand</th>\n",
       "      <th>Top BBand</th>\n",
       "      <th>Bot BBand</th>\n",
       "      <th>Volatility</th>\n",
       "      <th>...</th>\n",
       "      <th>ShortEMA</th>\n",
       "      <th>LongEMA</th>\n",
       "      <th>ShortMA</th>\n",
       "      <th>LongMA</th>\n",
       "      <th>MACD</th>\n",
       "      <th>ROC</th>\n",
       "      <th>SPY_returns</th>\n",
       "      <th>Treasury_Yield_10_Years</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-02-09</th>\n",
       "      <td>23.572500</td>\n",
       "      <td>23.985001</td>\n",
       "      <td>23.482500</td>\n",
       "      <td>23.747499</td>\n",
       "      <td>21.957256</td>\n",
       "      <td>177324800</td>\n",
       "      <td>24.216625</td>\n",
       "      <td>25.309459</td>\n",
       "      <td>23.123791</td>\n",
       "      <td>2.185667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.002611</td>\n",
       "      <td>24.404134</td>\n",
       "      <td>24.003333</td>\n",
       "      <td>24.404134</td>\n",
       "      <td>-0.401524</td>\n",
       "      <td>-6.339973</td>\n",
       "      <td>185.429993</td>\n",
       "      <td>1.729</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-02-10</th>\n",
       "      <td>23.980000</td>\n",
       "      <td>24.087500</td>\n",
       "      <td>23.525000</td>\n",
       "      <td>23.567499</td>\n",
       "      <td>21.790819</td>\n",
       "      <td>169374400</td>\n",
       "      <td>24.145500</td>\n",
       "      <td>25.212599</td>\n",
       "      <td>23.078400</td>\n",
       "      <td>2.134199</td>\n",
       "      <td>...</td>\n",
       "      <td>23.935670</td>\n",
       "      <td>24.342161</td>\n",
       "      <td>23.895625</td>\n",
       "      <td>24.297596</td>\n",
       "      <td>-0.406491</td>\n",
       "      <td>-5.199121</td>\n",
       "      <td>185.270004</td>\n",
       "      <td>1.705</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-02-11</th>\n",
       "      <td>23.447500</td>\n",
       "      <td>23.680000</td>\n",
       "      <td>23.147499</td>\n",
       "      <td>23.424999</td>\n",
       "      <td>21.659065</td>\n",
       "      <td>200298800</td>\n",
       "      <td>24.099375</td>\n",
       "      <td>25.206558</td>\n",
       "      <td>22.992191</td>\n",
       "      <td>2.214367</td>\n",
       "      <td>...</td>\n",
       "      <td>23.857106</td>\n",
       "      <td>24.274223</td>\n",
       "      <td>23.764583</td>\n",
       "      <td>24.210961</td>\n",
       "      <td>-0.417118</td>\n",
       "      <td>-6.290630</td>\n",
       "      <td>182.860001</td>\n",
       "      <td>1.644</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-02-12</th>\n",
       "      <td>23.547501</td>\n",
       "      <td>23.625000</td>\n",
       "      <td>23.252501</td>\n",
       "      <td>23.497499</td>\n",
       "      <td>21.726103</td>\n",
       "      <td>161405600</td>\n",
       "      <td>24.030250</td>\n",
       "      <td>25.106037</td>\n",
       "      <td>22.954463</td>\n",
       "      <td>2.151574</td>\n",
       "      <td>...</td>\n",
       "      <td>23.801782</td>\n",
       "      <td>24.216688</td>\n",
       "      <td>23.776458</td>\n",
       "      <td>24.146442</td>\n",
       "      <td>-0.414907</td>\n",
       "      <td>0.610147</td>\n",
       "      <td>186.630005</td>\n",
       "      <td>1.748</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-02-16</th>\n",
       "      <td>23.754999</td>\n",
       "      <td>24.212500</td>\n",
       "      <td>23.652500</td>\n",
       "      <td>24.160000</td>\n",
       "      <td>22.338657</td>\n",
       "      <td>196231600</td>\n",
       "      <td>24.024125</td>\n",
       "      <td>25.095483</td>\n",
       "      <td>22.952766</td>\n",
       "      <td>2.142717</td>\n",
       "      <td>...</td>\n",
       "      <td>23.856892</td>\n",
       "      <td>24.212489</td>\n",
       "      <td>23.829583</td>\n",
       "      <td>24.148269</td>\n",
       "      <td>-0.355597</td>\n",
       "      <td>2.710174</td>\n",
       "      <td>189.779999</td>\n",
       "      <td>1.778</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Open       High        Low      Close  Adj Close     Volume  \\\n",
       "Date                                                                           \n",
       "2016-02-09  23.572500  23.985001  23.482500  23.747499  21.957256  177324800   \n",
       "2016-02-10  23.980000  24.087500  23.525000  23.567499  21.790819  169374400   \n",
       "2016-02-11  23.447500  23.680000  23.147499  23.424999  21.659065  200298800   \n",
       "2016-02-12  23.547501  23.625000  23.252501  23.497499  21.726103  161405600   \n",
       "2016-02-16  23.754999  24.212500  23.652500  24.160000  22.338657  196231600   \n",
       "\n",
       "            Mid BBand  Top BBand  Bot BBand  Volatility  ...   ShortEMA  \\\n",
       "Date                                                     ...              \n",
       "2016-02-09  24.216625  25.309459  23.123791    2.185667  ...  24.002611   \n",
       "2016-02-10  24.145500  25.212599  23.078400    2.134199  ...  23.935670   \n",
       "2016-02-11  24.099375  25.206558  22.992191    2.214367  ...  23.857106   \n",
       "2016-02-12  24.030250  25.106037  22.954463    2.151574  ...  23.801782   \n",
       "2016-02-16  24.024125  25.095483  22.952766    2.142717  ...  23.856892   \n",
       "\n",
       "              LongEMA    ShortMA     LongMA      MACD       ROC  SPY_returns  \\\n",
       "Date                                                                           \n",
       "2016-02-09  24.404134  24.003333  24.404134 -0.401524 -6.339973   185.429993   \n",
       "2016-02-10  24.342161  23.895625  24.297596 -0.406491 -5.199121   185.270004   \n",
       "2016-02-11  24.274223  23.764583  24.210961 -0.417118 -6.290630   182.860001   \n",
       "2016-02-12  24.216688  23.776458  24.146442 -0.414907  0.610147   186.630005   \n",
       "2016-02-16  24.212489  23.829583  24.148269 -0.355597  2.710174   189.779999   \n",
       "\n",
       "            Treasury_Yield_10_Years  Sentiment  Target  \n",
       "Date                                                    \n",
       "2016-02-09                    1.729          0     2.0  \n",
       "2016-02-10                    1.705          0     2.0  \n",
       "2016-02-11                    1.644          0     1.0  \n",
       "2016-02-12                    1.748          0     2.0  \n",
       "2016-02-16                    1.778          0     2.0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.dropna()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Val-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(data)*.6)\n",
    "val_size = int(len(data) *.1)\n",
    "test_size = len(data)-train_size-val_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(data[\"Close\"], color = \"blue\", alpha = .5)\n",
    "xcoords = [data.index[train_size], data.index[train_size+val_size]]\n",
    "for xc in xcoords:\n",
    "    plt.axvline(x=xc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Mid BBand</th>\n",
       "      <th>Top BBand</th>\n",
       "      <th>Bot BBand</th>\n",
       "      <th>Volatility</th>\n",
       "      <th>...</th>\n",
       "      <th>ShortEMA</th>\n",
       "      <th>LongEMA</th>\n",
       "      <th>ShortMA</th>\n",
       "      <th>LongMA</th>\n",
       "      <th>MACD</th>\n",
       "      <th>ROC</th>\n",
       "      <th>SPY_returns</th>\n",
       "      <th>Treasury_Yield_10_Years</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-02-09</th>\n",
       "      <td>23.572500</td>\n",
       "      <td>23.985001</td>\n",
       "      <td>23.482500</td>\n",
       "      <td>23.747499</td>\n",
       "      <td>21.957256</td>\n",
       "      <td>177324800</td>\n",
       "      <td>24.216625</td>\n",
       "      <td>25.309459</td>\n",
       "      <td>23.123791</td>\n",
       "      <td>2.185667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.002611</td>\n",
       "      <td>24.404134</td>\n",
       "      <td>24.003333</td>\n",
       "      <td>24.404134</td>\n",
       "      <td>-0.401524</td>\n",
       "      <td>-6.339973</td>\n",
       "      <td>185.429993</td>\n",
       "      <td>1.729</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-02-10</th>\n",
       "      <td>23.980000</td>\n",
       "      <td>24.087500</td>\n",
       "      <td>23.525000</td>\n",
       "      <td>23.567499</td>\n",
       "      <td>21.790819</td>\n",
       "      <td>169374400</td>\n",
       "      <td>24.145500</td>\n",
       "      <td>25.212599</td>\n",
       "      <td>23.078400</td>\n",
       "      <td>2.134199</td>\n",
       "      <td>...</td>\n",
       "      <td>23.935670</td>\n",
       "      <td>24.342161</td>\n",
       "      <td>23.895625</td>\n",
       "      <td>24.297596</td>\n",
       "      <td>-0.406491</td>\n",
       "      <td>-5.199121</td>\n",
       "      <td>185.270004</td>\n",
       "      <td>1.705</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-02-11</th>\n",
       "      <td>23.447500</td>\n",
       "      <td>23.680000</td>\n",
       "      <td>23.147499</td>\n",
       "      <td>23.424999</td>\n",
       "      <td>21.659065</td>\n",
       "      <td>200298800</td>\n",
       "      <td>24.099375</td>\n",
       "      <td>25.206558</td>\n",
       "      <td>22.992191</td>\n",
       "      <td>2.214367</td>\n",
       "      <td>...</td>\n",
       "      <td>23.857106</td>\n",
       "      <td>24.274223</td>\n",
       "      <td>23.764583</td>\n",
       "      <td>24.210961</td>\n",
       "      <td>-0.417118</td>\n",
       "      <td>-6.290630</td>\n",
       "      <td>182.860001</td>\n",
       "      <td>1.644</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-02-12</th>\n",
       "      <td>23.547501</td>\n",
       "      <td>23.625000</td>\n",
       "      <td>23.252501</td>\n",
       "      <td>23.497499</td>\n",
       "      <td>21.726103</td>\n",
       "      <td>161405600</td>\n",
       "      <td>24.030250</td>\n",
       "      <td>25.106037</td>\n",
       "      <td>22.954463</td>\n",
       "      <td>2.151574</td>\n",
       "      <td>...</td>\n",
       "      <td>23.801782</td>\n",
       "      <td>24.216688</td>\n",
       "      <td>23.776458</td>\n",
       "      <td>24.146442</td>\n",
       "      <td>-0.414907</td>\n",
       "      <td>0.610147</td>\n",
       "      <td>186.630005</td>\n",
       "      <td>1.748</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-02-16</th>\n",
       "      <td>23.754999</td>\n",
       "      <td>24.212500</td>\n",
       "      <td>23.652500</td>\n",
       "      <td>24.160000</td>\n",
       "      <td>22.338657</td>\n",
       "      <td>196231600</td>\n",
       "      <td>24.024125</td>\n",
       "      <td>25.095483</td>\n",
       "      <td>22.952766</td>\n",
       "      <td>2.142717</td>\n",
       "      <td>...</td>\n",
       "      <td>23.856892</td>\n",
       "      <td>24.212489</td>\n",
       "      <td>23.829583</td>\n",
       "      <td>24.148269</td>\n",
       "      <td>-0.355597</td>\n",
       "      <td>2.710174</td>\n",
       "      <td>189.779999</td>\n",
       "      <td>1.778</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Open       High        Low      Close  Adj Close     Volume  \\\n",
       "Date                                                                           \n",
       "2016-02-09  23.572500  23.985001  23.482500  23.747499  21.957256  177324800   \n",
       "2016-02-10  23.980000  24.087500  23.525000  23.567499  21.790819  169374400   \n",
       "2016-02-11  23.447500  23.680000  23.147499  23.424999  21.659065  200298800   \n",
       "2016-02-12  23.547501  23.625000  23.252501  23.497499  21.726103  161405600   \n",
       "2016-02-16  23.754999  24.212500  23.652500  24.160000  22.338657  196231600   \n",
       "\n",
       "            Mid BBand  Top BBand  Bot BBand  Volatility  ...   ShortEMA  \\\n",
       "Date                                                     ...              \n",
       "2016-02-09  24.216625  25.309459  23.123791    2.185667  ...  24.002611   \n",
       "2016-02-10  24.145500  25.212599  23.078400    2.134199  ...  23.935670   \n",
       "2016-02-11  24.099375  25.206558  22.992191    2.214367  ...  23.857106   \n",
       "2016-02-12  24.030250  25.106037  22.954463    2.151574  ...  23.801782   \n",
       "2016-02-16  24.024125  25.095483  22.952766    2.142717  ...  23.856892   \n",
       "\n",
       "              LongEMA    ShortMA     LongMA      MACD       ROC  SPY_returns  \\\n",
       "Date                                                                           \n",
       "2016-02-09  24.404134  24.003333  24.404134 -0.401524 -6.339973   185.429993   \n",
       "2016-02-10  24.342161  23.895625  24.297596 -0.406491 -5.199121   185.270004   \n",
       "2016-02-11  24.274223  23.764583  24.210961 -0.417118 -6.290630   182.860001   \n",
       "2016-02-12  24.216688  23.776458  24.146442 -0.414907  0.610147   186.630005   \n",
       "2016-02-16  24.212489  23.829583  24.148269 -0.355597  2.710174   189.779999   \n",
       "\n",
       "            Treasury_Yield_10_Years  Sentiment  Target  \n",
       "Date                                                    \n",
       "2016-02-09                    1.729          0     2.0  \n",
       "2016-02-10                    1.705          0     2.0  \n",
       "2016-02-11                    1.644          0     1.0  \n",
       "2016-02-12                    1.748          0     2.0  \n",
       "2016-02-16                    1.778          0     2.0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = data[:train_size]\n",
    "val_df = data[train_size: train_size+val_size]\n",
    "test_df = data[train_size+val_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Mid BBand</th>\n",
       "      <th>Top BBand</th>\n",
       "      <th>Bot BBand</th>\n",
       "      <th>Volatility</th>\n",
       "      <th>...</th>\n",
       "      <th>ShortEMA</th>\n",
       "      <th>LongEMA</th>\n",
       "      <th>ShortMA</th>\n",
       "      <th>LongMA</th>\n",
       "      <th>MACD</th>\n",
       "      <th>ROC</th>\n",
       "      <th>SPY_returns</th>\n",
       "      <th>Treasury_Yield_10_Years</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-02-09</th>\n",
       "      <td>23.572500</td>\n",
       "      <td>23.985001</td>\n",
       "      <td>23.482500</td>\n",
       "      <td>23.747499</td>\n",
       "      <td>21.957256</td>\n",
       "      <td>177324800</td>\n",
       "      <td>24.216625</td>\n",
       "      <td>25.309459</td>\n",
       "      <td>23.123791</td>\n",
       "      <td>2.185667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.002611</td>\n",
       "      <td>24.404134</td>\n",
       "      <td>24.003333</td>\n",
       "      <td>24.404134</td>\n",
       "      <td>-0.401524</td>\n",
       "      <td>-6.339973</td>\n",
       "      <td>185.429993</td>\n",
       "      <td>1.729</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-02-10</th>\n",
       "      <td>23.980000</td>\n",
       "      <td>24.087500</td>\n",
       "      <td>23.525000</td>\n",
       "      <td>23.567499</td>\n",
       "      <td>21.790819</td>\n",
       "      <td>169374400</td>\n",
       "      <td>24.145500</td>\n",
       "      <td>25.212599</td>\n",
       "      <td>23.078400</td>\n",
       "      <td>2.134199</td>\n",
       "      <td>...</td>\n",
       "      <td>23.935670</td>\n",
       "      <td>24.342161</td>\n",
       "      <td>23.895625</td>\n",
       "      <td>24.297596</td>\n",
       "      <td>-0.406491</td>\n",
       "      <td>-5.199121</td>\n",
       "      <td>185.270004</td>\n",
       "      <td>1.705</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-02-11</th>\n",
       "      <td>23.447500</td>\n",
       "      <td>23.680000</td>\n",
       "      <td>23.147499</td>\n",
       "      <td>23.424999</td>\n",
       "      <td>21.659065</td>\n",
       "      <td>200298800</td>\n",
       "      <td>24.099375</td>\n",
       "      <td>25.206558</td>\n",
       "      <td>22.992191</td>\n",
       "      <td>2.214367</td>\n",
       "      <td>...</td>\n",
       "      <td>23.857106</td>\n",
       "      <td>24.274223</td>\n",
       "      <td>23.764583</td>\n",
       "      <td>24.210961</td>\n",
       "      <td>-0.417118</td>\n",
       "      <td>-6.290630</td>\n",
       "      <td>182.860001</td>\n",
       "      <td>1.644</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-02-12</th>\n",
       "      <td>23.547501</td>\n",
       "      <td>23.625000</td>\n",
       "      <td>23.252501</td>\n",
       "      <td>23.497499</td>\n",
       "      <td>21.726103</td>\n",
       "      <td>161405600</td>\n",
       "      <td>24.030250</td>\n",
       "      <td>25.106037</td>\n",
       "      <td>22.954463</td>\n",
       "      <td>2.151574</td>\n",
       "      <td>...</td>\n",
       "      <td>23.801782</td>\n",
       "      <td>24.216688</td>\n",
       "      <td>23.776458</td>\n",
       "      <td>24.146442</td>\n",
       "      <td>-0.414907</td>\n",
       "      <td>0.610147</td>\n",
       "      <td>186.630005</td>\n",
       "      <td>1.748</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-02-16</th>\n",
       "      <td>23.754999</td>\n",
       "      <td>24.212500</td>\n",
       "      <td>23.652500</td>\n",
       "      <td>24.160000</td>\n",
       "      <td>22.338657</td>\n",
       "      <td>196231600</td>\n",
       "      <td>24.024125</td>\n",
       "      <td>25.095483</td>\n",
       "      <td>22.952766</td>\n",
       "      <td>2.142717</td>\n",
       "      <td>...</td>\n",
       "      <td>23.856892</td>\n",
       "      <td>24.212489</td>\n",
       "      <td>23.829583</td>\n",
       "      <td>24.148269</td>\n",
       "      <td>-0.355597</td>\n",
       "      <td>2.710174</td>\n",
       "      <td>189.779999</td>\n",
       "      <td>1.778</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Open       High        Low      Close  Adj Close     Volume  \\\n",
       "Date                                                                           \n",
       "2016-02-09  23.572500  23.985001  23.482500  23.747499  21.957256  177324800   \n",
       "2016-02-10  23.980000  24.087500  23.525000  23.567499  21.790819  169374400   \n",
       "2016-02-11  23.447500  23.680000  23.147499  23.424999  21.659065  200298800   \n",
       "2016-02-12  23.547501  23.625000  23.252501  23.497499  21.726103  161405600   \n",
       "2016-02-16  23.754999  24.212500  23.652500  24.160000  22.338657  196231600   \n",
       "\n",
       "            Mid BBand  Top BBand  Bot BBand  Volatility  ...   ShortEMA  \\\n",
       "Date                                                     ...              \n",
       "2016-02-09  24.216625  25.309459  23.123791    2.185667  ...  24.002611   \n",
       "2016-02-10  24.145500  25.212599  23.078400    2.134199  ...  23.935670   \n",
       "2016-02-11  24.099375  25.206558  22.992191    2.214367  ...  23.857106   \n",
       "2016-02-12  24.030250  25.106037  22.954463    2.151574  ...  23.801782   \n",
       "2016-02-16  24.024125  25.095483  22.952766    2.142717  ...  23.856892   \n",
       "\n",
       "              LongEMA    ShortMA     LongMA      MACD       ROC  SPY_returns  \\\n",
       "Date                                                                           \n",
       "2016-02-09  24.404134  24.003333  24.404134 -0.401524 -6.339973   185.429993   \n",
       "2016-02-10  24.342161  23.895625  24.297596 -0.406491 -5.199121   185.270004   \n",
       "2016-02-11  24.274223  23.764583  24.210961 -0.417118 -6.290630   182.860001   \n",
       "2016-02-12  24.216688  23.776458  24.146442 -0.414907  0.610147   186.630005   \n",
       "2016-02-16  24.212489  23.829583  24.148269 -0.355597  2.710174   189.779999   \n",
       "\n",
       "            Treasury_Yield_10_Years  Sentiment  Target  \n",
       "Date                                                    \n",
       "2016-02-09                    1.729          0     2.0  \n",
       "2016-02-10                    1.705          0     2.0  \n",
       "2016-02-11                    1.644          0     1.0  \n",
       "2016-02-12                    1.748          0     2.0  \n",
       "2016-02-16                    1.778          0     2.0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_cols = list(train_df.columns)[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rudra\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3678: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[col] = igetitem(value, i)\n"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "train_df[norm_cols] = scaler.fit_transform(train_df[norm_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Sentiment\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Mid BBand</th>\n",
       "      <th>Top BBand</th>\n",
       "      <th>Bot BBand</th>\n",
       "      <th>Volatility</th>\n",
       "      <th>...</th>\n",
       "      <th>ShortEMA</th>\n",
       "      <th>LongEMA</th>\n",
       "      <th>ShortMA</th>\n",
       "      <th>LongMA</th>\n",
       "      <th>MACD</th>\n",
       "      <th>ROC</th>\n",
       "      <th>SPY_returns</th>\n",
       "      <th>Treasury_Yield_10_Years</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-02-09</th>\n",
       "      <td>0.030473</td>\n",
       "      <td>0.030113</td>\n",
       "      <td>0.031787</td>\n",
       "      <td>0.032809</td>\n",
       "      <td>0.027043</td>\n",
       "      <td>0.319345</td>\n",
       "      <td>0.021908</td>\n",
       "      <td>0.025419</td>\n",
       "      <td>0.054489</td>\n",
       "      <td>0.080737</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015121</td>\n",
       "      <td>0.012607</td>\n",
       "      <td>0.022834</td>\n",
       "      <td>0.018283</td>\n",
       "      <td>0.521036</td>\n",
       "      <td>0.313447</td>\n",
       "      <td>0.021569</td>\n",
       "      <td>0.194325</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-02-10</th>\n",
       "      <td>0.042051</td>\n",
       "      <td>0.033004</td>\n",
       "      <td>0.032998</td>\n",
       "      <td>0.027729</td>\n",
       "      <td>0.022294</td>\n",
       "      <td>0.300093</td>\n",
       "      <td>0.019710</td>\n",
       "      <td>0.022536</td>\n",
       "      <td>0.053094</td>\n",
       "      <td>0.077094</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013084</td>\n",
       "      <td>0.010651</td>\n",
       "      <td>0.019582</td>\n",
       "      <td>0.014961</td>\n",
       "      <td>0.519940</td>\n",
       "      <td>0.347543</td>\n",
       "      <td>0.020227</td>\n",
       "      <td>0.181478</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-02-11</th>\n",
       "      <td>0.026921</td>\n",
       "      <td>0.021509</td>\n",
       "      <td>0.022236</td>\n",
       "      <td>0.023707</td>\n",
       "      <td>0.018534</td>\n",
       "      <td>0.374977</td>\n",
       "      <td>0.018285</td>\n",
       "      <td>0.022356</td>\n",
       "      <td>0.050446</td>\n",
       "      <td>0.082768</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010694</td>\n",
       "      <td>0.008506</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.012261</td>\n",
       "      <td>0.517595</td>\n",
       "      <td>0.314922</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.148822</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-02-12</th>\n",
       "      <td>0.029763</td>\n",
       "      <td>0.019958</td>\n",
       "      <td>0.025230</td>\n",
       "      <td>0.025753</td>\n",
       "      <td>0.020447</td>\n",
       "      <td>0.280796</td>\n",
       "      <td>0.016148</td>\n",
       "      <td>0.019364</td>\n",
       "      <td>0.049287</td>\n",
       "      <td>0.078324</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009010</td>\n",
       "      <td>0.006690</td>\n",
       "      <td>0.015984</td>\n",
       "      <td>0.010249</td>\n",
       "      <td>0.518083</td>\n",
       "      <td>0.521163</td>\n",
       "      <td>0.031641</td>\n",
       "      <td>0.204497</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-02-16</th>\n",
       "      <td>0.035658</td>\n",
       "      <td>0.036530</td>\n",
       "      <td>0.036633</td>\n",
       "      <td>0.044451</td>\n",
       "      <td>0.037926</td>\n",
       "      <td>0.365128</td>\n",
       "      <td>0.015959</td>\n",
       "      <td>0.019050</td>\n",
       "      <td>0.049235</td>\n",
       "      <td>0.077697</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010687</td>\n",
       "      <td>0.006557</td>\n",
       "      <td>0.017588</td>\n",
       "      <td>0.010306</td>\n",
       "      <td>0.531168</td>\n",
       "      <td>0.583926</td>\n",
       "      <td>0.058078</td>\n",
       "      <td>0.220557</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Open      High       Low     Close  Adj Close    Volume  \\\n",
       "Date                                                                      \n",
       "2016-02-09  0.030473  0.030113  0.031787  0.032809   0.027043  0.319345   \n",
       "2016-02-10  0.042051  0.033004  0.032998  0.027729   0.022294  0.300093   \n",
       "2016-02-11  0.026921  0.021509  0.022236  0.023707   0.018534  0.374977   \n",
       "2016-02-12  0.029763  0.019958  0.025230  0.025753   0.020447  0.280796   \n",
       "2016-02-16  0.035658  0.036530  0.036633  0.044451   0.037926  0.365128   \n",
       "\n",
       "            Mid BBand  Top BBand  Bot BBand  Volatility  ...  ShortEMA  \\\n",
       "Date                                                     ...             \n",
       "2016-02-09   0.021908   0.025419   0.054489    0.080737  ...  0.015121   \n",
       "2016-02-10   0.019710   0.022536   0.053094    0.077094  ...  0.013084   \n",
       "2016-02-11   0.018285   0.022356   0.050446    0.082768  ...  0.010694   \n",
       "2016-02-12   0.016148   0.019364   0.049287    0.078324  ...  0.009010   \n",
       "2016-02-16   0.015959   0.019050   0.049235    0.077697  ...  0.010687   \n",
       "\n",
       "             LongEMA   ShortMA    LongMA      MACD       ROC  SPY_returns  \\\n",
       "Date                                                                        \n",
       "2016-02-09  0.012607  0.022834  0.018283  0.521036  0.313447     0.021569   \n",
       "2016-02-10  0.010651  0.019582  0.014961  0.519940  0.347543     0.020227   \n",
       "2016-02-11  0.008506  0.015625  0.012261  0.517595  0.314922     0.000000   \n",
       "2016-02-12  0.006690  0.015984  0.010249  0.518083  0.521163     0.031641   \n",
       "2016-02-16  0.006557  0.017588  0.010306  0.531168  0.583926     0.058078   \n",
       "\n",
       "            Treasury_Yield_10_Years  Sentiment  Target  \n",
       "Date                                                    \n",
       "2016-02-09                 0.194325        0.0     2.0  \n",
       "2016-02-10                 0.181478        0.0     2.0  \n",
       "2016-02-11                 0.148822        0.0     1.0  \n",
       "2016-02-12                 0.204497        0.0     2.0  \n",
       "2016-02-16                 0.220557        0.0     2.0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Mid BBand</th>\n",
       "      <th>Top BBand</th>\n",
       "      <th>Bot BBand</th>\n",
       "      <th>Volatility</th>\n",
       "      <th>...</th>\n",
       "      <th>RSI</th>\n",
       "      <th>ShortEMA</th>\n",
       "      <th>LongEMA</th>\n",
       "      <th>ShortMA</th>\n",
       "      <th>LongMA</th>\n",
       "      <th>MACD</th>\n",
       "      <th>ROC</th>\n",
       "      <th>SPY_returns</th>\n",
       "      <th>Treasury_Yield_10_Years</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-02-09</th>\n",
       "      <td>0.030473</td>\n",
       "      <td>0.030113</td>\n",
       "      <td>0.031787</td>\n",
       "      <td>0.032809</td>\n",
       "      <td>0.027043</td>\n",
       "      <td>0.319345</td>\n",
       "      <td>0.021908</td>\n",
       "      <td>0.025419</td>\n",
       "      <td>0.054489</td>\n",
       "      <td>0.080737</td>\n",
       "      <td>...</td>\n",
       "      <td>0.270334</td>\n",
       "      <td>0.015121</td>\n",
       "      <td>0.012607</td>\n",
       "      <td>0.022834</td>\n",
       "      <td>0.018283</td>\n",
       "      <td>0.521036</td>\n",
       "      <td>0.313447</td>\n",
       "      <td>0.021569</td>\n",
       "      <td>0.194325</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-02-10</th>\n",
       "      <td>0.042051</td>\n",
       "      <td>0.033004</td>\n",
       "      <td>0.032998</td>\n",
       "      <td>0.027729</td>\n",
       "      <td>0.022294</td>\n",
       "      <td>0.300093</td>\n",
       "      <td>0.019710</td>\n",
       "      <td>0.022536</td>\n",
       "      <td>0.053094</td>\n",
       "      <td>0.077094</td>\n",
       "      <td>...</td>\n",
       "      <td>0.253002</td>\n",
       "      <td>0.013084</td>\n",
       "      <td>0.010651</td>\n",
       "      <td>0.019582</td>\n",
       "      <td>0.014961</td>\n",
       "      <td>0.519940</td>\n",
       "      <td>0.347543</td>\n",
       "      <td>0.020227</td>\n",
       "      <td>0.181478</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-02-11</th>\n",
       "      <td>0.026921</td>\n",
       "      <td>0.021509</td>\n",
       "      <td>0.022236</td>\n",
       "      <td>0.023707</td>\n",
       "      <td>0.018534</td>\n",
       "      <td>0.374977</td>\n",
       "      <td>0.018285</td>\n",
       "      <td>0.022356</td>\n",
       "      <td>0.050446</td>\n",
       "      <td>0.082768</td>\n",
       "      <td>...</td>\n",
       "      <td>0.239033</td>\n",
       "      <td>0.010694</td>\n",
       "      <td>0.008506</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.012261</td>\n",
       "      <td>0.517595</td>\n",
       "      <td>0.314922</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.148822</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-02-12</th>\n",
       "      <td>0.029763</td>\n",
       "      <td>0.019958</td>\n",
       "      <td>0.025230</td>\n",
       "      <td>0.025753</td>\n",
       "      <td>0.020447</td>\n",
       "      <td>0.280796</td>\n",
       "      <td>0.016148</td>\n",
       "      <td>0.019364</td>\n",
       "      <td>0.049287</td>\n",
       "      <td>0.078324</td>\n",
       "      <td>...</td>\n",
       "      <td>0.251244</td>\n",
       "      <td>0.009010</td>\n",
       "      <td>0.006690</td>\n",
       "      <td>0.015984</td>\n",
       "      <td>0.010249</td>\n",
       "      <td>0.518083</td>\n",
       "      <td>0.521163</td>\n",
       "      <td>0.031641</td>\n",
       "      <td>0.204497</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-02-16</th>\n",
       "      <td>0.035658</td>\n",
       "      <td>0.036530</td>\n",
       "      <td>0.036633</td>\n",
       "      <td>0.044451</td>\n",
       "      <td>0.037926</td>\n",
       "      <td>0.365128</td>\n",
       "      <td>0.015959</td>\n",
       "      <td>0.019050</td>\n",
       "      <td>0.049235</td>\n",
       "      <td>0.077697</td>\n",
       "      <td>...</td>\n",
       "      <td>0.355804</td>\n",
       "      <td>0.010687</td>\n",
       "      <td>0.006557</td>\n",
       "      <td>0.017588</td>\n",
       "      <td>0.010306</td>\n",
       "      <td>0.531168</td>\n",
       "      <td>0.583926</td>\n",
       "      <td>0.058078</td>\n",
       "      <td>0.220557</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Open      High       Low     Close  Adj Close    Volume  \\\n",
       "Date                                                                      \n",
       "2016-02-09  0.030473  0.030113  0.031787  0.032809   0.027043  0.319345   \n",
       "2016-02-10  0.042051  0.033004  0.032998  0.027729   0.022294  0.300093   \n",
       "2016-02-11  0.026921  0.021509  0.022236  0.023707   0.018534  0.374977   \n",
       "2016-02-12  0.029763  0.019958  0.025230  0.025753   0.020447  0.280796   \n",
       "2016-02-16  0.035658  0.036530  0.036633  0.044451   0.037926  0.365128   \n",
       "\n",
       "            Mid BBand  Top BBand  Bot BBand  Volatility  ...       RSI  \\\n",
       "Date                                                     ...             \n",
       "2016-02-09   0.021908   0.025419   0.054489    0.080737  ...  0.270334   \n",
       "2016-02-10   0.019710   0.022536   0.053094    0.077094  ...  0.253002   \n",
       "2016-02-11   0.018285   0.022356   0.050446    0.082768  ...  0.239033   \n",
       "2016-02-12   0.016148   0.019364   0.049287    0.078324  ...  0.251244   \n",
       "2016-02-16   0.015959   0.019050   0.049235    0.077697  ...  0.355804   \n",
       "\n",
       "            ShortEMA   LongEMA   ShortMA    LongMA      MACD       ROC  \\\n",
       "Date                                                                     \n",
       "2016-02-09  0.015121  0.012607  0.022834  0.018283  0.521036  0.313447   \n",
       "2016-02-10  0.013084  0.010651  0.019582  0.014961  0.519940  0.347543   \n",
       "2016-02-11  0.010694  0.008506  0.015625  0.012261  0.517595  0.314922   \n",
       "2016-02-12  0.009010  0.006690  0.015984  0.010249  0.518083  0.521163   \n",
       "2016-02-16  0.010687  0.006557  0.017588  0.010306  0.531168  0.583926   \n",
       "\n",
       "            SPY_returns  Treasury_Yield_10_Years  Sentiment  \n",
       "Date                                                         \n",
       "2016-02-09     0.021569                 0.194325        0.0  \n",
       "2016-02-10     0.020227                 0.181478        0.0  \n",
       "2016-02-11     0.000000                 0.148822        0.0  \n",
       "2016-02-12     0.031641                 0.204497        0.0  \n",
       "2016-02-16     0.058078                 0.220557        0.0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x, train_y = train_df.iloc[:,:-1],train_df.iloc[:,-1]\n",
    "train_x.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rudra\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3678: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[col] = igetitem(value, i)\n",
      "C:\\Users\\rudra\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3678: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[col] = igetitem(value, i)\n"
     ]
    }
   ],
   "source": [
    "scaler_val = MinMaxScaler()\n",
    "val_df[norm_cols] = scaler_val.fit_transform(val_df[norm_cols])\n",
    "\n",
    "scaler_test = MinMaxScaler()\n",
    "test_df[norm_cols] = scaler_test.fit_transform(test_df[norm_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_x, val_y = val_df.iloc[:,:-1],val_df.iloc[:,-1]\n",
    "test_x, test_y = test_df.iloc[:,:-1],test_df.iloc[:,-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(data, window = 7):\n",
    "    seq = []\n",
    "    for i in range(len(data)-window):\n",
    "        record = []\n",
    "        for j in range(window):\n",
    "            \n",
    "            record.append(data.iloc[i+j].values)\n",
    "        seq.append(record)\n",
    "\n",
    "    \n",
    "    return seq \n",
    "\n",
    "\n",
    "train_seq = create_sequences(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_input(seq, y, window=7):\n",
    "    y = y[window:]\n",
    "    assert len(seq) == len(y)\n",
    "    seq_tensor = [torch.tensor(l) for l in seq]\n",
    "    y_tensor = [torch.tensor(l).unsqueeze(0) for l in y]\n",
    "    inout_seq = list(zip(seq_tensor, y_tensor))\n",
    "    return inout_seq\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = train_y[7:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_seq) == len(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_seq, train_y_seq = np.array(train_seq), np.array(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(882, 7, 23)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_seq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cover to tensors\n",
    "train_seq_tensor = [torch.tensor(l) for l in train_seq]\n",
    "train_y_tensor = [torch.tensor(l).unsqueeze(0) for l in train_y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y_tensor[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inout_seq = list(zip(train_seq_tensor, train_y_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.0305, 0.0301, 0.0318, 0.0328, 0.0270, 0.3193, 0.0219, 0.0254, 0.0545,\n",
       "          0.0807, 0.0219, 0.0238, 0.0291, 0.2703, 0.0151, 0.0126, 0.0228, 0.0183,\n",
       "          0.5210, 0.3134, 0.0216, 0.1943, 0.0000],\n",
       "         [0.0421, 0.0330, 0.0330, 0.0277, 0.0223, 0.3001, 0.0197, 0.0225, 0.0531,\n",
       "          0.0771, 0.0197, 0.0212, 0.0273, 0.2530, 0.0131, 0.0107, 0.0196, 0.0150,\n",
       "          0.5199, 0.3475, 0.0202, 0.1815, 0.0000],\n",
       "         [0.0269, 0.0215, 0.0222, 0.0237, 0.0185, 0.3750, 0.0183, 0.0224, 0.0504,\n",
       "          0.0828, 0.0183, 0.0204, 0.0252, 0.2390, 0.0107, 0.0085, 0.0156, 0.0123,\n",
       "          0.5176, 0.3149, 0.0000, 0.1488, 0.0000],\n",
       "         [0.0298, 0.0200, 0.0252, 0.0258, 0.0204, 0.2808, 0.0161, 0.0194, 0.0493,\n",
       "          0.0783, 0.0161, 0.0178, 0.0236, 0.2512, 0.0090, 0.0067, 0.0160, 0.0102,\n",
       "          0.5181, 0.5212, 0.0316, 0.2045, 0.0000],\n",
       "         [0.0357, 0.0365, 0.0366, 0.0445, 0.0379, 0.3651, 0.0160, 0.0190, 0.0492,\n",
       "          0.0777, 0.0160, 0.0176, 0.0234, 0.3558, 0.0107, 0.0066, 0.0176, 0.0103,\n",
       "          0.5312, 0.5839, 0.0581, 0.2206, 0.0000],\n",
       "         [0.0474, 0.0461, 0.0476, 0.0549, 0.0477, 0.3245, 0.0165, 0.0202, 0.0491,\n",
       "          0.0807, 0.0165, 0.0185, 0.0237, 0.4076, 0.0138, 0.0073, 0.0181, 0.0107,\n",
       "          0.5488, 0.5269, 0.0841, 0.2425, 0.0000],\n",
       "         [0.0628, 0.0509, 0.0472, 0.0418, 0.0354, 0.2679, 0.0163, 0.0200, 0.0490,\n",
       "          0.0804, 0.0163, 0.0182, 0.0235, 0.3492, 0.0143, 0.0069, 0.0180, 0.0100,\n",
       "          0.5552, 0.4977, 0.0775, 0.2104, 0.0000]], dtype=torch.float64),\n",
       " tensor([2.]))"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_inout_seq[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_FEATURES = 23\n",
    "BATCH_SIZE = 1\n",
    "class NetworkClassifier(torch.nn.Module):\n",
    "    def __init__(self, input_size = NUM_FEATURES, hidden_size = 128, output_size = 3, batch_size = BATCH_SIZE, dropout = 0.2, num_layers=2):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size #num of features\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size    \n",
    "        self.batch_size = batch_size\n",
    "        self.num_layers = num_layers  \n",
    "\n",
    "        self.lstm = torch.nn.LSTM(self.input_size, self.hidden_size, self.num_layers, dropout=dropout)\n",
    "        self.linear = torch.nn.Linear(self.hidden_size, self.output_size)\n",
    "        # a new hidden-state (the LSTM requires, unlike RNNs, two hidden-states in a tuple)\n",
    "        \n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        # h_t = torch.zeros(input_seq.size(0), self.hidden_size, dtype=torch.float32)\n",
    "        # c_t = torch.zeros(input_seq.size(0), self.hidden_size, dtype=torch.float32)\n",
    "        hidden = (torch.zeros(self.num_layers, self.batch_size, self.hidden_size), torch.zeros(self.num_layers, self.batch_size, self.hidden_size))\n",
    "\n",
    "\n",
    "        #print(self.hidden_cell[0].shape)\n",
    "        #print(input_seq.shape)\n",
    "        lstm_out, hidden = self.lstm(input_seq, hidden)\n",
    "        \n",
    "        # x contains the output states of every timestep, \n",
    "        # for classifiction we mostly just want the last one\n",
    "        #print(out.shape)\n",
    "        \n",
    "        #lstm_out = lstm_out[:, -1] \n",
    "        \n",
    "        #out = out.view(len(input_seq),-1)\n",
    "        #print(out.shape)\n",
    "        #out = self.linear(out)\n",
    "        \n",
    "        out = self.linear(hidden[0])\n",
    "        # print(out)\n",
    "        return out[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_seq = create_sequences(val_x)\n",
    "val_inout_seq = create_model_input(val_seq, val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_seq = create_sequences(test_x)\n",
    "test_inout_seq = create_model_input(test_seq, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nmodel = NetworkClassifier()\\n                    loss_func = torch.nn.CrossEntropyLoss()\\n                    opt = torch.optim.Adam(model.parameters(),lr=lr)\\n\\n\\n                    log_name = datetime.now().strftime(\"%m-%d-%H%M\")\\n                    for epoch in range(epochs):\\n                        print(\"epoch\", epoch)\\n                        train_loss_total = 0\\n\\n                        train_logger = tb.SummaryWriter(\\'./writer/\\' + log_name + \\'/train\\', flush_secs = 1)\\n                        for i, (x, y) in enumerate(train_inout_seq):\\n                            model.train()\\n                        \\n                            opt.zero_grad()\\n                            \\n                            x = x.view(len(x), 1, -1)\\n                            #print(x.shape)\\n\\n                            #print(\"running\")\\n                            out = model(x.float())\\n                            # print(out.shape)\\n                            # print(y.shape)\\n\\n                            # print(out)\\n                            y_pred = torch.argmax(out, dim=1)\\n                            # print(torch.argmax(out, dim=1))\\n\\n                            loss = loss_func(out,y.type(torch.LongTensor))\\n                            loss.backward()\\n                            opt.step()\\n\\n                            train_loss_total += loss.item()\\n                        \\n\\n                        model.eval()\\n                        #val_conf = ConfusionMatrix()\\n                        val_logger = tb.SummaryWriter(\\'./writer/\\' + log_name + \\'/val\\', flush_secs = 1)\\n                        val_loss_total = 0\\n                        for i, (x, y) in enumerate(test_inout_seq):\\n                            #print(x)\\n                            #print(model(x.view(len(x), 1, -1).float()))\\n                            out = model(x.view(len(x), 1, -1).float())\\n                            loss = loss_func(out,y.type(torch.LongTensor))\\n\\n                            val_loss_total += loss.item()\\n\\n                        avg_train_loss = train_loss_total/len(train_inout_seq)\\n                        avg_val_loss = val_loss_total/len(val_inout_seq)\\n                        \\n                        train_logger.add_scalar(\"Loss_train\", avg_train_loss, epoch)\\n                        val_logger.add_scalar(\"Loss_val\", avg_val_loss, epoch)\\n'"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "model = NetworkClassifier()\n",
    "                    loss_func = torch.nn.CrossEntropyLoss()\n",
    "                    opt = torch.optim.Adam(model.parameters(),lr=lr)\n",
    "\n",
    "\n",
    "                    log_name = datetime.now().strftime(\"%m-%d-%H%M\")\n",
    "                    for epoch in range(epochs):\n",
    "                        print(\"epoch\", epoch)\n",
    "                        train_loss_total = 0\n",
    "\n",
    "                        train_logger = tb.SummaryWriter('./writer/' + log_name + '/train', flush_secs = 1)\n",
    "                        for i, (x, y) in enumerate(train_inout_seq):\n",
    "                            model.train()\n",
    "                        \n",
    "                            opt.zero_grad()\n",
    "                            \n",
    "                            x = x.view(len(x), 1, -1)\n",
    "                            #print(x.shape)\n",
    "\n",
    "                            #print(\"running\")\n",
    "                            out = model(x.float())\n",
    "                            # print(out.shape)\n",
    "                            # print(y.shape)\n",
    "\n",
    "                            # print(out)\n",
    "                            y_pred = torch.argmax(out, dim=1)\n",
    "                            # print(torch.argmax(out, dim=1))\n",
    "\n",
    "                            loss = loss_func(out,y.type(torch.LongTensor))\n",
    "                            loss.backward()\n",
    "                            opt.step()\n",
    "\n",
    "                            train_loss_total += loss.item()\n",
    "                        \n",
    "\n",
    "                        model.eval()\n",
    "                        #val_conf = ConfusionMatrix()\n",
    "                        val_logger = tb.SummaryWriter('./writer/' + log_name + '/val', flush_secs = 1)\n",
    "                        val_loss_total = 0\n",
    "                        for i, (x, y) in enumerate(test_inout_seq):\n",
    "                            #print(x)\n",
    "                            #print(model(x.view(len(x), 1, -1).float()))\n",
    "                            out = model(x.view(len(x), 1, -1).float())\n",
    "                            loss = loss_func(out,y.type(torch.LongTensor))\n",
    "\n",
    "                            val_loss_total += loss.item()\n",
    "\n",
    "                        avg_train_loss = train_loss_total/len(train_inout_seq)\n",
    "                        avg_val_loss = val_loss_total/len(val_inout_seq)\n",
    "                        \n",
    "                        train_logger.add_scalar(\"Loss_train\", avg_train_loss, epoch)\n",
    "                        val_logger.add_scalar(\"Loss_val\", avg_val_loss, epoch)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n",
      "0\n",
      "1\n",
      "128\n",
      "0\n",
      "2\n",
      "128\n",
      "0\n",
      "3\n",
      "128\n",
      "0\n",
      "4\n",
      "128\n",
      "0.2\n",
      "1\n",
      "128\n",
      "0.2\n",
      "2\n",
      "hs_128_do_0.2_nl_2_lr_0.01_opt_adam_03-30-1100\n",
      "epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rudra\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:60: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\__init__.py\u001b[0m in \u001b[0;36mtf\u001b[1;34m()\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m         \u001b[1;32mfrom\u001b[0m \u001b[0mtensorboard\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnotf\u001b[0m  \u001b[1;31m# noqa: F401\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'notf' from 'tensorboard.compat' (C:\\Users\\rudra\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\__init__.py)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-94-628d51216382>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     45\u001b[0m                             \u001b[0mtrain_loss_total\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m                             \u001b[0mtrain_logger\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSummaryWriter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./writer/'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mlog_name\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'/train'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflush_secs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m                             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_inout_seq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m                                 \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\utils\\tensorboard\\writer.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, log_dir, comment, purge_step, max_queue, flush_secs, filename_suffix)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;31m# and recreated later as needed.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfile_writer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall_writers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 225\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_file_writer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m         \u001b[1;31m# Create default bins for histograms, see generate_testdata.py in tensorflow/tensorboard\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\utils\\tensorboard\\writer.py\u001b[0m in \u001b[0;36m_get_file_writer\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    254\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall_writers\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfile_writer\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m             self.file_writer = FileWriter(self.log_dir, self.max_queue,\n\u001b[1;32m--> 256\u001b[1;33m                                           self.flush_secs, self.filename_suffix)\n\u001b[0m\u001b[0;32m    257\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall_writers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfile_writer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_logdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfile_writer\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpurge_step\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\utils\\tensorboard\\writer.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, log_dir, max_queue, flush_secs, filename_suffix)\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[0mlog_dir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m         self.event_writer = EventFileWriter(\n\u001b[1;32m---> 66\u001b[1;33m             log_dir, max_queue, flush_secs, filename_suffix)\n\u001b[0m\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_logdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorboard\\summary\\writer\\event_file_writer.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, logdir, max_queue_size, flush_secs, filename_suffix)\u001b[0m\n\u001b[0;32m     70\u001b[0m         \"\"\"\n\u001b[0;32m     71\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_logdir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlogdir\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogdir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m         self._file_name = (\n\u001b[0;32m     74\u001b[0m             os.path.join(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorboard\\lazy.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, attr_name)\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[1;32mclass\u001b[0m \u001b[0mLazyModule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModuleType\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m             \u001b[1;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattr_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mload_once\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattr_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[1;32mdef\u001b[0m \u001b[0m__dir__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorboard\\lazy.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(arg)\u001b[0m\n\u001b[0;32m     95\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mlock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnothing\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mnothing\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 97\u001b[1;33m                     \u001b[0mcache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     98\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorboard\\lazy.py\u001b[0m in \u001b[0;36mload_once\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     48\u001b[0m             \u001b[0mload_once\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloading\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m                 \u001b[0mmodule\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m                 \u001b[0mload_once\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloading\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\__init__.py\u001b[0m in \u001b[0;36mtf\u001b[1;34m()\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m             \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msys\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_sys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodule_util\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_module_util\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlazy_loader\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLazyLoader\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_LazyLoader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdistribute\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_column\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfeature_column_lib\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfeature_column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;31m# See b/110718070#comment18 for more details about this import.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_layer\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\models.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmetrics_module\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0moptimizer_v1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfunctional\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mkeras_tensor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnode\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnode_module\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtraining\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtraining_lib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtraining_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaving\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaved_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnetwork_serialization\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmixed_precision\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mloss_scale_optimizer\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mlso\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmixed_precision\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaving\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mhdf5_format\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaving\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msave\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaving\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaved_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mjson_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\hdf5_format.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;31m# pylint: disable=g-import-not-at-top\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m   \u001b[1;32mimport\u001b[0m \u001b[0mh5py\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m   \u001b[0mHDF5_OBJECT_HEADER_LIMIT\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m64512\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;31m# --- Public API --------------------------------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mh5a\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh5d\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh5ds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh5fd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh5g\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh5r\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh5s\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh5t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh5p\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh5z\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh5pl\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_hl\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfilters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh5py\\h5f.pyx\u001b[0m in \u001b[0;36minit h5py.h5f\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_spec\u001b[1;34m(name, path, target)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36mfind_spec\u001b[1;34m(cls, fullname, path, target)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36m_get_spec\u001b[1;34m(cls, fullname, path, target)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36mfind_spec\u001b[1;34m(self, fullname, target)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36m_path_stat\u001b[1;34m(path)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 40\n",
    "\n",
    "#before stopped: hidden_sizes = [32, 64, 128, 256]\n",
    "#second stop: hidden_sizes = [128, 256]\n",
    "#hidden_sizes = [256]\n",
    "\n",
    "#hidden_sizes = [32, 64, 128, 256]\n",
    "hidden_sizes = [128, 256]\n",
    "n_dropouts = [0, .2, .4, .6]\n",
    "num_layers = [1,2,3,4]\n",
    "\n",
    "lrs = [.01,.001,.0001]\n",
    "opt_texts = [\"adam\", \"sgd\"]\n",
    "\n",
    "#stopped at: hs_128_do_0.2_nl_2_lr_0.0001_opt_adam_03-04-1053\n",
    "\n",
    "for hidden_size in hidden_sizes:\n",
    "    for dropout in n_dropouts:\n",
    "        \n",
    "        for num_layer in num_layers:\n",
    "            print(hidden_size)\n",
    "            print(dropout)\n",
    "            print(num_layer)\n",
    "            model = NetworkClassifier(hidden_size=hidden_size, dropout=dropout, num_layers=num_layer)\n",
    "            \n",
    "            for lr in lrs:\n",
    "                for opt_text in opt_texts:\n",
    "                    if opt_text == \"adam\":\n",
    "                        opt = torch.optim.Adam(model.parameters(),lr=lr)\n",
    "                    else:\n",
    "                        opt = torch.optim.SGD(model.parameters(),lr=lr)\n",
    "\n",
    "                    if (hidden_size == 128 and dropout != 0 and num_layer != 1) or (hidden_size != 128):\n",
    "                        # UGHHHHHHHH WHYYYYYY WERE THESE LINES HEREEEEEEEE ?!??!?!?!?!?\n",
    "                        \n",
    "                        #model = NetworkClassifier()\n",
    "                        loss_func = torch.nn.CrossEntropyLoss()\n",
    "                        # opt = torch.optim.Adam(model.parameters(),lr=lr)\n",
    "\n",
    "\n",
    "                        log_name = 'hs_' + str(hidden_size) + \"_do_\" + str(dropout) + \"_nl_\"+ str(num_layer) + \"_lr_\" + str(lr) + \"_opt_\" + opt_text + \"_\" + datetime.now().strftime(\"%m-%d-%H%M\")\n",
    "                        print(log_name)\n",
    "                        for epoch in range(epochs):\n",
    "                            print(\"epoch\", epoch)\n",
    "                            train_loss_total = 0\n",
    "\n",
    "                            train_logger = tb.SummaryWriter('./writer/' + log_name + '/train', flush_secs = 1)\n",
    "                            for i, (x, y) in enumerate(train_inout_seq):\n",
    "                                model.train()\n",
    "                            \n",
    "                                opt.zero_grad()\n",
    "                                \n",
    "                                x = x.view(len(x), 1, -1)\n",
    "                                #print(x.shape)\n",
    "\n",
    "                                #print(\"running\")\n",
    "                                out = model(x.float())\n",
    "                                # print(out.shape)\n",
    "                                # print(y.shape)\n",
    "\n",
    "                                # print(out)\n",
    "                                y_pred = torch.argmax(out, dim=1)\n",
    "                                # print(torch.argmax(out, dim=1))\n",
    "\n",
    "                                loss = loss_func(out,y.type(torch.LongTensor))\n",
    "                                loss.backward()\n",
    "                                opt.step()\n",
    "\n",
    "                                train_loss_total += loss.item()\n",
    "                            \n",
    "\n",
    "                            model.eval()\n",
    "                            #val_conf = ConfusionMatrix()\n",
    "                            val_logger = tb.SummaryWriter('./writer/' + log_name + '/val', flush_secs = 1)\n",
    "                            val_loss_total = 0\n",
    "                            for i, (x, y) in enumerate(test_inout_seq):\n",
    "                                #print(x)\n",
    "                                #print(model(x.view(len(x), 1, -1).float()))\n",
    "                                out = model(x.view(len(x), 1, -1).float())\n",
    "                                loss = loss_func(out,y.type(torch.LongTensor))\n",
    "\n",
    "                                val_loss_total += loss.item()\n",
    "\n",
    "                            avg_train_loss = train_loss_total/len(train_inout_seq)\n",
    "                            avg_val_loss = val_loss_total/len(val_inout_seq)\n",
    "                            \n",
    "                            train_logger.add_scalar(\"Loss_train\", avg_train_loss, epoch)\n",
    "                            val_logger.add_scalar(\"Loss_val\", avg_val_loss, epoch)\n",
    "                        \n",
    "                        torch.save(model, \"models/%s.pt\" % log_name)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Mid BBand</th>\n",
       "      <th>Top BBand</th>\n",
       "      <th>Bot BBand</th>\n",
       "      <th>Volatility</th>\n",
       "      <th>...</th>\n",
       "      <th>ShortEMA</th>\n",
       "      <th>LongEMA</th>\n",
       "      <th>ShortMA</th>\n",
       "      <th>LongMA</th>\n",
       "      <th>MACD</th>\n",
       "      <th>ROC</th>\n",
       "      <th>SPY_returns</th>\n",
       "      <th>Treasury_Yield_10_Years</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-02-09</th>\n",
       "      <td>0.030473</td>\n",
       "      <td>0.030113</td>\n",
       "      <td>0.031787</td>\n",
       "      <td>0.032809</td>\n",
       "      <td>0.027043</td>\n",
       "      <td>0.319345</td>\n",
       "      <td>0.021908</td>\n",
       "      <td>0.025419</td>\n",
       "      <td>0.054489</td>\n",
       "      <td>0.080737</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015121</td>\n",
       "      <td>0.012607</td>\n",
       "      <td>0.022834</td>\n",
       "      <td>0.018283</td>\n",
       "      <td>0.521036</td>\n",
       "      <td>0.313447</td>\n",
       "      <td>0.021569</td>\n",
       "      <td>0.194325</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-02-10</th>\n",
       "      <td>0.042051</td>\n",
       "      <td>0.033004</td>\n",
       "      <td>0.032998</td>\n",
       "      <td>0.027729</td>\n",
       "      <td>0.022294</td>\n",
       "      <td>0.300093</td>\n",
       "      <td>0.019710</td>\n",
       "      <td>0.022536</td>\n",
       "      <td>0.053094</td>\n",
       "      <td>0.077094</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013084</td>\n",
       "      <td>0.010651</td>\n",
       "      <td>0.019582</td>\n",
       "      <td>0.014961</td>\n",
       "      <td>0.519940</td>\n",
       "      <td>0.347543</td>\n",
       "      <td>0.020227</td>\n",
       "      <td>0.181478</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-02-11</th>\n",
       "      <td>0.026921</td>\n",
       "      <td>0.021509</td>\n",
       "      <td>0.022236</td>\n",
       "      <td>0.023707</td>\n",
       "      <td>0.018534</td>\n",
       "      <td>0.374977</td>\n",
       "      <td>0.018285</td>\n",
       "      <td>0.022356</td>\n",
       "      <td>0.050446</td>\n",
       "      <td>0.082768</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010694</td>\n",
       "      <td>0.008506</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.012261</td>\n",
       "      <td>0.517595</td>\n",
       "      <td>0.314922</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.148822</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-02-12</th>\n",
       "      <td>0.029763</td>\n",
       "      <td>0.019958</td>\n",
       "      <td>0.025230</td>\n",
       "      <td>0.025753</td>\n",
       "      <td>0.020447</td>\n",
       "      <td>0.280796</td>\n",
       "      <td>0.016148</td>\n",
       "      <td>0.019364</td>\n",
       "      <td>0.049287</td>\n",
       "      <td>0.078324</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009010</td>\n",
       "      <td>0.006690</td>\n",
       "      <td>0.015984</td>\n",
       "      <td>0.010249</td>\n",
       "      <td>0.518083</td>\n",
       "      <td>0.521163</td>\n",
       "      <td>0.031641</td>\n",
       "      <td>0.204497</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-02-16</th>\n",
       "      <td>0.035658</td>\n",
       "      <td>0.036530</td>\n",
       "      <td>0.036633</td>\n",
       "      <td>0.044451</td>\n",
       "      <td>0.037926</td>\n",
       "      <td>0.365128</td>\n",
       "      <td>0.015959</td>\n",
       "      <td>0.019050</td>\n",
       "      <td>0.049235</td>\n",
       "      <td>0.077697</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010687</td>\n",
       "      <td>0.006557</td>\n",
       "      <td>0.017588</td>\n",
       "      <td>0.010306</td>\n",
       "      <td>0.531168</td>\n",
       "      <td>0.583926</td>\n",
       "      <td>0.058078</td>\n",
       "      <td>0.220557</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Open      High       Low     Close  Adj Close    Volume  \\\n",
       "Date                                                                      \n",
       "2016-02-09  0.030473  0.030113  0.031787  0.032809   0.027043  0.319345   \n",
       "2016-02-10  0.042051  0.033004  0.032998  0.027729   0.022294  0.300093   \n",
       "2016-02-11  0.026921  0.021509  0.022236  0.023707   0.018534  0.374977   \n",
       "2016-02-12  0.029763  0.019958  0.025230  0.025753   0.020447  0.280796   \n",
       "2016-02-16  0.035658  0.036530  0.036633  0.044451   0.037926  0.365128   \n",
       "\n",
       "            Mid BBand  Top BBand  Bot BBand  Volatility  ...  ShortEMA  \\\n",
       "Date                                                     ...             \n",
       "2016-02-09   0.021908   0.025419   0.054489    0.080737  ...  0.015121   \n",
       "2016-02-10   0.019710   0.022536   0.053094    0.077094  ...  0.013084   \n",
       "2016-02-11   0.018285   0.022356   0.050446    0.082768  ...  0.010694   \n",
       "2016-02-12   0.016148   0.019364   0.049287    0.078324  ...  0.009010   \n",
       "2016-02-16   0.015959   0.019050   0.049235    0.077697  ...  0.010687   \n",
       "\n",
       "             LongEMA   ShortMA    LongMA      MACD       ROC  SPY_returns  \\\n",
       "Date                                                                        \n",
       "2016-02-09  0.012607  0.022834  0.018283  0.521036  0.313447     0.021569   \n",
       "2016-02-10  0.010651  0.019582  0.014961  0.519940  0.347543     0.020227   \n",
       "2016-02-11  0.008506  0.015625  0.012261  0.517595  0.314922     0.000000   \n",
       "2016-02-12  0.006690  0.015984  0.010249  0.518083  0.521163     0.031641   \n",
       "2016-02-16  0.006557  0.017588  0.010306  0.531168  0.583926     0.058078   \n",
       "\n",
       "            Treasury_Yield_10_Years  Sentiment  Target  \n",
       "Date                                                    \n",
       "2016-02-09                 0.194325        0.0     2.0  \n",
       "2016-02-10                 0.181478        0.0     2.0  \n",
       "2016-02-11                 0.148822        0.0     1.0  \n",
       "2016-02-12                 0.204497        0.0     2.0  \n",
       "2016-02-16                 0.220557        0.0     2.0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(889, 24)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rudra\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3678: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[col] = igetitem(value, i)\n"
     ]
    }
   ],
   "source": [
    "train_df[norm_cols] = scaler.inverse_transform(train_df[norm_cols] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rudra\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3678: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[col] = igetitem(value, i)\n",
      "C:\\Users\\rudra\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3678: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[col] = igetitem(value, i)\n",
      "C:\\Users\\rudra\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3678: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[col] = igetitem(value, i)\n"
     ]
    }
   ],
   "source": [
    "train_df[norm_cols] = scaler.inverse_transform(train_df[norm_cols])\n",
    "val_df[norm_cols] = scaler_val.inverse_transform(val_df[norm_cols])\n",
    "test_df[norm_cols] = scaler_test.inverse_transform(test_df[norm_cols])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "889"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_preds(df_set, preds, window_size = 7, show_true=True):\n",
    "\n",
    "    \n",
    "\n",
    "    df = df_set.copy()\n",
    "    #df = df[7:train_size]\n",
    "    df[\"Buy\"] = [df.iloc[i][\"Close\"] if df.iloc[i][\"Target\"] == 1.0 else np.nan for i in range(len(df[\"Target\"]))]\n",
    "    df[\"Sell\"] = [df.iloc[i][\"Close\"] if df.iloc[i][\"Target\"] == 0.0 else np.nan for i in range(len(df[\"Target\"]))]\n",
    "\n",
    "    df[\"Pred Buy\"] = [np.nan] * window_size + [df.iloc[i+window_size][\"Close\"] if preds[i] == 1 else np.nan for i in range(len(preds))]\n",
    "    df[\"Pred Sell\"] = [np.nan] * window_size + [df.iloc[i+window_size][\"Close\"] if preds[i] == 0 else np.nan for i in range(len(preds))]\n",
    "\n",
    "    #df[\"Sell\"] = [df[\"Close\"] if i == 0.0 else np.nan for i in df[\"Target\"]]\n",
    "    fig = plt.figure(figsize=(8, 6))\n",
    "    plt.plot(df[\"Close\"], color = \"blue\", alpha = .5)\n",
    "    \n",
    "    if show_true:\n",
    "        if(not df[\"Buy\"].isnull().all()):\n",
    "            plt.scatter(df.index, df[\"Buy\"], color = 'green', marker=\"^\", alpha=1)\n",
    "        if(not df[\"Sell\"].isnull().all()):\n",
    "            plt.scatter(df.index, df[\"Sell\"], color = 'red', marker=\"v\", alpha=1)\n",
    "\n",
    "    if(not df[\"Pred Buy\"].isnull().all()):\n",
    "        plt.scatter(df.index, df[\"Pred Buy\"], color = 'purple', marker=\"^\", alpha=1)\n",
    "    if(not df[\"Pred Sell\"].isnull().all()):\n",
    "        plt.scatter(df.index, df[\"Pred Sell\"], color = 'orange', marker=\"v\", alpha=1)\n",
    "    \n",
    "    #plt.axvline(x=data.index[train_size])\n",
    "    #print(type(df.index[0]))\n",
    "    #plt.axis([pd.Timestamp('2020-01-01'), pd.Timestamp('2020-03-01'), 0, 1])\n",
    "    \n",
    "\n",
    "    plt.show() \n",
    "    # fig.savefig('ML_charts/{}_target_chart.png'.format(symbol))\n",
    "   \n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "#overfits at 100 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"models/hs_256_do_0.6_nl_4_lr_0.01_opt_adam_03-05-1429.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0    327\n",
       "0.0     20\n",
       "1.0     17\n",
       "Name: Target, dtype: int64"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = 1-(train_df[\"Target\"].value_counts()[2]/len(train_df[\"Target\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9532967032967032"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = [1-(train_df[\"Target\"].value_counts()[class_num]/len(train_df[\"Target\"])) for class_num in range(3)]\n",
    "class_weights=torch.tensor(class_weights,dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = [1/(train_df[\"Target\"].value_counts()[class_num]) for class_num in range(3)]\n",
    "class_weights=torch.tensor(class_weights,dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.8583, 0.8661, 0.2756])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.8583, 0.8661, 0.2756])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = [0.99, 0.99, .01]\n",
    "class_weights=torch.tensor(class_weights,dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "0.8039377969467923 0.8117755668383118\n",
      "epoch 1\n",
      "0.7899804777231346 0.8035343240761588\n",
      "epoch 2\n",
      "0.7881165246844563 0.7993294317671593\n",
      "epoch 3\n",
      "0.7886649185027125 0.8007887225624517\n",
      "epoch 4\n",
      "0.7883316771953014 0.7949088458896528\n",
      "epoch 5\n",
      "0.786635971393715 0.7943679605815428\n",
      "epoch 6\n",
      "0.7847022839617026 0.7937961389832463\n",
      "epoch 7\n",
      "0.7826097190988307 0.7938239910501115\n",
      "epoch 8\n",
      "0.7855145710598584 0.7932724413719583\n",
      "epoch 9\n",
      "0.7832827599816311 0.7939778382473803\n",
      "epoch 10\n",
      "0.78436877639318 0.7929846386537485\n",
      "epoch 11\n",
      "0.7839765071936475 0.7930145587058778\n",
      "epoch 12\n",
      "0.7834836270769978 0.7929772571891758\n",
      "epoch 13\n",
      "0.7827258880953399 0.7928417597679381\n",
      "epoch 14\n",
      "0.7827851254653498 0.7928767356466739\n",
      "epoch 15\n",
      "0.7824918559146306 0.7928199218520036\n",
      "epoch 16\n",
      "0.7817604378913265 0.7927663913855316\n",
      "epoch 17\n",
      "0.7833805424657538 0.7929695149262747\n",
      "epoch 18\n",
      "0.7820838030909194 0.7928044683967076\n",
      "epoch 19\n",
      "0.7825060322914534 0.7928451350394715\n",
      "epoch 20\n",
      "0.782350758643918 0.7927898872405925\n",
      "epoch 21\n",
      "0.7828193493440848 0.7927702401123994\n",
      "epoch 22\n",
      "0.7820474014463338 0.7928054260869398\n",
      "epoch 23\n",
      "0.7816893750645406 0.7928349316542875\n",
      "epoch 24\n",
      "0.7824407943150624 0.7927965530266998\n",
      "epoch 25\n",
      "0.7823192708346308 0.7927937378697362\n",
      "epoch 26\n",
      "0.7817707995033047 0.7928071692057536\n",
      "epoch 27\n",
      "0.7816481962968973 0.7927845365612219\n",
      "epoch 28\n",
      "0.7820787350404289 0.7928357206760569\n",
      "epoch 29\n",
      "0.7821958223336678 0.7927652314199624\n",
      "epoch 30\n",
      "0.78208874088296 0.7927732700151755\n",
      "epoch 31\n",
      "0.7818464033998329 0.7927820445797967\n",
      "epoch 32\n",
      "0.7819903994701347 0.7927845285293904\n",
      "epoch 33\n",
      "0.7821781011699549 0.7928143319085981\n",
      "epoch 34\n",
      "0.7818590965366958 0.7928384675624522\n",
      "epoch 35\n",
      "0.7823106808051501 0.7928132632522719\n",
      "epoch 36\n",
      "0.7824491874025522 0.7928156404630512\n",
      "epoch 37\n",
      "0.7818831600704972 0.7927883421698361\n",
      "epoch 38\n",
      "0.7818826965801841 0.792775848655836\n",
      "epoch 39\n",
      "0.781443814605542 0.7929494930497298\n",
      "epoch 40\n",
      "0.782111639473714 0.7929363937665385\n",
      "epoch 41\n",
      "0.7815595374288472 0.7929212478458458\n",
      "epoch 42\n",
      "0.782292973005177 0.7929204922195867\n",
      "epoch 43\n",
      "0.782337221614763 0.7929840952369338\n",
      "epoch 44\n",
      "0.7828207713575049 0.7929850142475561\n",
      "epoch 45\n",
      "0.7813586123338362 0.7929980638602101\n",
      "epoch 46\n",
      "0.7823643197818678 0.7928894449633064\n",
      "epoch 47\n",
      "0.8076631734063194 0.7927212125443398\n",
      "epoch 48\n",
      "0.7821052151134495 0.792764647421262\n",
      "epoch 49\n",
      "0.7825324798589931 0.7927661660715197\n",
      "epoch 50\n",
      "0.7814552713008154 0.7928436552801876\n",
      "epoch 51\n",
      "0.7821093782478449 0.7927694327019631\n",
      "epoch 52\n",
      "0.7812891629209865 0.7930077310149551\n",
      "epoch 53\n",
      "0.7818500389790589 0.792783981308024\n",
      "epoch 54\n",
      "0.78191577418456 0.7928105345431794\n",
      "epoch 55\n",
      "0.7820780319826943 0.792825941287034\n",
      "epoch 56\n",
      "0.7816241555203116 0.793380822061647\n",
      "epoch 57\n",
      "0.7828643465258367 0.7928244530731905\n",
      "epoch 58\n",
      "0.782016950940329 0.7928729596290183\n",
      "epoch 59\n",
      "0.7818889313138802 0.7929811236706186\n",
      "epoch 60\n",
      "0.7825894762599279 0.7927985489368439\n",
      "epoch 61\n",
      "0.7821135426324511 0.7930099862687131\n",
      "epoch 62\n",
      "0.7818342131180287 0.7930812353783465\n",
      "epoch 63\n",
      "0.7815362914315427 0.7933430375782311\n",
      "epoch 64\n",
      "0.7817988272866154 0.7936040942973279\n",
      "epoch 65\n",
      "0.7815029623996373 0.7934178397165123\n",
      "epoch 66\n",
      "0.7818711921572685 0.7932857450441266\n",
      "epoch 67\n",
      "0.7834431635650918 0.7928952149888302\n",
      "epoch 68\n",
      "0.7826687540529537 0.792827418932678\n",
      "epoch 69\n",
      "0.7810723764522005 0.7942718819100806\n",
      "epoch 70\n",
      "0.7814831369030638 0.7936152230340539\n",
      "epoch 71\n",
      "0.7836759602334223 0.7932741390475144\n",
      "epoch 72\n",
      "0.7829625487428944 0.7928762558504199\n",
      "epoch 73\n",
      "0.7814314850603913 0.7930104666990592\n",
      "epoch 74\n",
      "0.7825546132531566 0.7940402715764148\n",
      "epoch 75\n",
      "0.7812880979103296 0.7954333441477295\n",
      "epoch 76\n",
      "0.7855679700298915 0.7927731579922616\n",
      "epoch 77\n",
      "0.7818465156822788 0.7930051929561804\n",
      "epoch 78\n",
      "0.7844146120946964 0.7930734535903795\n",
      "epoch 79\n",
      "0.7829899962932344 0.7935376114456366\n",
      "epoch 80\n",
      "0.784892428843748 0.7931664406407809\n",
      "epoch 81\n",
      "0.7824455554050113 0.7930164696476983\n",
      "epoch 82\n",
      "0.7811511906197552 0.7929944924428953\n",
      "epoch 83\n",
      "0.7833669160296317 0.7930999780800325\n",
      "epoch 84\n",
      "0.7819572804060653 0.7931709048595834\n",
      "epoch 85\n",
      "0.7826091914085034 0.7929804604104225\n",
      "epoch 86\n",
      "0.7821509655303155 0.792848804741041\n",
      "epoch 87\n",
      "0.782536632282123 0.7927683264228469\n",
      "epoch 88\n",
      "0.7826881306478226 0.7928063778589803\n",
      "epoch 89\n",
      "0.781758395452348 0.7927650669787792\n",
      "epoch 90\n",
      "0.7817251341345629 0.7927819078272962\n",
      "epoch 91\n",
      "0.7815656565687283 0.792885366483783\n",
      "epoch 92\n",
      "0.7819412478716735 0.7932766760494692\n",
      "epoch 93\n",
      "0.7839575015734923 0.7931313941664729\n",
      "epoch 94\n",
      "0.7823878369397588 0.7930131691990169\n",
      "epoch 95\n",
      "0.7812475837817808 0.7931883504204716\n",
      "epoch 96\n",
      "0.7829096234844926 0.7935663326412228\n",
      "epoch 97\n",
      "0.7833428129452427 0.7931109174346247\n",
      "epoch 98\n",
      "0.7807261243361194 0.7933319348392757\n",
      "epoch 99\n",
      "0.7823981756086793 0.7934940932913029\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "lr = .001\n",
    "#model = NetworkClassifier(hidden_size = 64, dropout=.2, num_layers=2)\n",
    "model = NetworkClassifier(hidden_size = 256, num_layers = 2, dropout=.4)\n",
    "\n",
    "\n",
    "opt = torch.optim.Adam(model.parameters(),lr=lr)\n",
    "\n",
    "#trying decay\n",
    "#decayRate = 0.96\n",
    "#lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer=opt, gamma=decayRate)\n",
    "\n",
    "loss_func = torch.nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "\n",
    "#log_name = 'hs_' + str(hidden_size) + \"_do_\" + str(dropout) + \"_nl_\"+ str(num_layer) + \"_lr_\" + str(lr) + \"_opt_\" + opt_text + \"_\" + datetime.now().strftime(\"%m-%d-%H%M\")\n",
    "log_name = \"weighted_loss\"\n",
    "for epoch in range(epochs):\n",
    "    print(\"epoch\", epoch)\n",
    "    train_loss_total = 0\n",
    "    model.train()\n",
    "    train_logger = tb.SummaryWriter('./writer/' + log_name + '/train', flush_secs = 1)\n",
    "    for i, (x, y) in enumerate(train_inout_seq):\n",
    "        \n",
    "    \n",
    "        opt.zero_grad()\n",
    "        \n",
    "        x = x.view(len(x), 1, -1)\n",
    "        #print(x.shape)\n",
    "\n",
    "        #print(\"running\")\n",
    "        out = model(x.float())\n",
    "        # print(out.shape)\n",
    "        # print(y.shape)\n",
    "\n",
    "        # print(out)\n",
    "        y_pred = torch.argmax(out, dim=1)\n",
    "        # print(torch.argmax(out, dim=1))\n",
    "\n",
    "        loss = loss_func(out,y.type(torch.LongTensor))\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        #lr_scheduler.step()\n",
    "        train_loss_total += loss.item()\n",
    "    \n",
    "\n",
    "    model.eval()\n",
    "    #val_conf = ConfusionMatrix()\n",
    "    val_logger = tb.SummaryWriter('./writer/' + log_name + '/val', flush_secs = 1)\n",
    "    val_loss_total = 0\n",
    "    for i, (x, y) in enumerate(val_inout_seq):\n",
    "        #print(x)\n",
    "        #print(model(x.view(len(x), 1, -1).float()))\n",
    "        out = model(x.view(len(x), 1, -1).float())\n",
    "        loss = loss_func(out,y.type(torch.LongTensor))\n",
    "\n",
    "        val_loss_total += loss.item()\n",
    "\n",
    "    avg_train_loss = train_loss_total/len(train_inout_seq)\n",
    "    avg_val_loss = val_loss_total/len(val_inout_seq)\n",
    "    \n",
    "    train_logger.add_scalar(\"Loss_train\", avg_train_loss, epoch)\n",
    "    val_logger.add_scalar(\"Loss_val\", avg_val_loss, epoch)\n",
    "\n",
    "    print(avg_train_loss, avg_val_loss)\n",
    "\n",
    "torch.save(model, \"models/%s.pt\" % log_name)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 1, 2}\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "preds = []\n",
    "\n",
    "for i, (x, y) in enumerate(train_inout_seq):\n",
    "    #print(x)\n",
    "    #print(model(x.view(len(x), 1, -1).float()))\n",
    "    preds.append(torch.argmax(model(x.view(len(x), 1, -1).float())).item())\n",
    "\n",
    "print(set(preds))\n",
    "\n",
    "plot_preds(train_df,preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{2}\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "preds = []\n",
    "\n",
    "for i, (x, y) in enumerate(val_inout_seq):\n",
    "    #print(x)\n",
    "    #print(model(x.view(len(x), 1, -1).float()))\n",
    "    preds.append(torch.argmax(model(x.view(len(x), 1, -1).float())).item())\n",
    "\n",
    "\n",
    "print(set(preds))\n",
    "plot_preds(val_df,preds)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "preds = []\n",
    "\n",
    "for i, (x, y) in enumerate(test_inout_seq):\n",
    "    #print(x)\n",
    "    #print(model(x.view(len(x), 1, -1).float()))\n",
    "    preds.append(torch.argmax(model(x.view(len(x), 1, -1).float())).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_preds(test_df,preds, show_true=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model hyperparater tuning\n",
    "# metric needed to see how well model is doing (amount profit, grace period of true days)\n",
    "# regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_pred_profit(df, preds, window_size = 7, num_shares=1):\n",
    "    df[\"Pred Buy\"] = [np.nan] * window_size + [df.iloc[i+window_size][\"Close\"] if preds[i] == 1 else np.nan for i in range(len(preds))]\n",
    "    df[\"Pred Sell\"] = [np.nan] * window_size + [df.iloc[i+window_size][\"Close\"] if preds[i] == 0 else np.nan for i in range(len(preds))]\n",
    "\n",
    "    pred_buy_share = []\n",
    "    pred_sell_share = []\n",
    "    \n",
    "    bought = False\n",
    "    inventory = num_shares\n",
    "    total_profit = 0\n",
    "    buy_in = 0\n",
    "    sell_out = 0\n",
    "    for i in range(len(df)):\n",
    "        if (not math.isnan(df[\"Pred Buy\"][i]) and inventory > 0):\n",
    "        #if (not math.isnan(df[\"Pred Buy\"][i]) and not bought):\n",
    "            buy_in = df[\"Pred Buy\"][i]\n",
    "            bought=True\n",
    "            inventory -= 1\n",
    "        \n",
    "        if (not math.isnan(df[\"Pred Sell\"][i]) and inventory <= num_shares):\n",
    "        #if (not math.isnan(df[\"Pred Sell\"][i]) and bought):\n",
    "            sell_out = df[\"Pred Sell\"][i]\n",
    "            bought=False\n",
    "            inventory += 1\n",
    "\n",
    "\n",
    "        if (buy_in != 0 and sell_out != 0):\n",
    "            profit = sell_out - buy_in\n",
    "            total_profit += profit\n",
    "            buy_in = 0\n",
    "            sell_out = 0\n",
    "    \n",
    "    buy_hold_profit = df[\"Close\"][-1] - df[\"Close\"][window_size]\n",
    "\n",
    "    return total_profit, buy_hold_profit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "single positional indexer is out-of-bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-86-1ce55bf2e92d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcalc_pred_profit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-85-8679a51c5bc3>\u001b[0m in \u001b[0;36mcalc_pred_profit\u001b[1;34m(df, preds, window_size, num_shares)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcalc_pred_profit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwindow_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m7\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_shares\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Pred Buy\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mwindow_size\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mwindow_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Close\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mpreds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnan\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Pred Sell\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mwindow_size\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mwindow_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Close\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mpreds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnan\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mpred_buy_share\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-85-8679a51c5bc3>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcalc_pred_profit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwindow_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m7\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_shares\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Pred Buy\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mwindow_size\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mwindow_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Close\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mpreds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnan\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Pred Sell\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mwindow_size\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mwindow_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Close\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mpreds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnan\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mpred_buy_share\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    929\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    930\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 931\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    932\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    933\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1564\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1565\u001b[0m             \u001b[1;31m# validate the location\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1566\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1567\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1568\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ixs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_validate_integer\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1498\u001b[0m         \u001b[0mlen_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1499\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mlen_axis\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mlen_axis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1500\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"single positional indexer is out-of-bounds\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1501\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1502\u001b[0m     \u001b[1;31m# -------------------------------------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: single positional indexer is out-of-bounds"
     ]
    }
   ],
   "source": [
    "calc_pred_profit(val_df, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maybe add time since last buy as a feature????"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "64444d065e0769d6cad3d7e49e95b26475484a957c8d7a96f3c4bb6d664eb5c8"
  },
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
